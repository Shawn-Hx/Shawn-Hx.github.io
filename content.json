{"pages":[{"title":"","text":"Basic 黄潇 （Shawn Huang） 1997.10.14 Education2015 - 2019 南京大学 软件学院 学士 2019 - now 清华大学 软件学院 工程硕士 Experience2018.7 - 2018.10 实习于 苏州微软工程院 Apache Flink Contributor 目前专注于流处理资源调度优化 Skills Language：Java, Python, C Framework：Flink, Spring Boot Database：MySQL, SQLite VCS：Git Tools：Vim, zsh, Docker OS：Arch Linux Hobbies 阅读 电影 魔方 Dota2 云玩家","link":"/about/index.html"}],"posts":[{"title":"Hello World","text":"关于博客很早就有了写博客的想法，但是耽搁到大三下才写下这第一篇博客，原因大概有这么几点。 最主要的原因是懒。我一直是个极其懒惰的人，微博只有转发，也从不发说说和朋友圈，更别说发布和更新博客了。 不仅如此，写博客还是一件极其麻烦的事情。如果要写博客，我是肯定不会在诸如CSDN这样的博客网站上写的，不仅界面丑陋而且充斥着各种抄袭、误导人的文章。既然如此那就得自己建站，买域名、买服务器，加上之后的部署和维护，极其麻烦，所以也一直没有动手。 当然还有很重要的一个问题是：博客应该写什么？ 看过阮一峰、廖雪峰、耗子哥、垠神等诸多dalao的博客，深感自己当前知识的匮乏、对技术理解之浅，对比之下觉得自己写出的技术博客必然会十分肤浅。而如果是记录一些踩过的坑，或是写课堂学习笔记又觉得没有太多的价值，也提不起写博客的兴趣，总之就这样一直搁置了下来。 直到前一阵子听说，GitHub Pages可以免费搭建个人博客，绑定域名，甚至能免费开启https，我这才又重新想起了写博客的事。几乎每天都在用的GitHub有这么方便的工具，我居然现在才知道，确实有点孤陋寡闻了。恰好最近在微信读书上看书，苦于看书时前面看后面忘，把博客作为读书总结归纳的地方再好不过。 创建仓库话不多说，我先改掉了GitHub的用户名（原来的用户名有点蠢），按username.github.io的命名要求新建了仓库。配置好了Jekyll，并学习了下基本的用法，用Jekyll创建了自己的博客并push到了我的仓库中。 JekyllJekyll是一个简单的Blog生成工具，只生成静态网页，但可以配合第三方服务。Jekyll可以免费部署在Github上。 Jekyll的安装很简单。首先需要在Mac上安装Xcode和Command-Line Tools。Xcode可以直接在App Store搜索下载，下载完成后在终端执行xcode-select --install后根据提示即可安装Command-Line Tools。 Mac OS X自带了Ruby，直接在终端下执行gem install jekyll即可完成安装。 如果系统自带的Ruby版本较低，安装时可能会提示出错，这时需要安装rvm，使用rvm安装和管理新版本Ruby。这个知乎提问的回答讲解比较具体。 接下来直接终端执行jekyll new myblog，jekyll会自动创建一个内容符合博客网站目录结构的myblog目录。在生成的myblog目录下，执行jekyll serve，即可在本地浏览器访问http://localhost:4000进行预览。 如果中途遇到缺少依赖的提示，使用gem install [package]安装即可。 最后将myblog目录下的内容push到之前创建的github仓库中，便可以访问到博客内容。 模版Jekyll有诸多主题模版，Github提供了一些可选的主题，可以在仓库设置中选择。除此之外，这里也提供了大量主题可供选用。 目前我使用的是默认的minima主题，也许以后有空的时候会摸索一下换个好看一点的。 域名GitHub Pages给博客提供的默认域名即为仓库名username.github.io。如果需要自定义域名，可以在项目根目录下创建CNAME文件，输入不带协议的自定义域名即可。 我是在GoDaddy购买的域名，原本在万网上发现.com .cn .net常用域名都已经被注册了（意料之中），后来发现.me域名不错，用在个人博客恰到好处，而万网并不提供.me域名的购买，于是最终在GoDaddy花了￥24购买了首年的huangxiao.me域名。 GitHub Pages从5月1日起可以为自定义域名支持HTTPS。新的IP地址不仅支持HTTPS，而且可以通过CDN加快访问速度，同时还能防范DDoS攻击。 如果自定义域名使用CNAME或ALIAS记录，那么仅需在仓库设置中勾选Enforce HTTPS选项即可。 如果自定义域名使用A记录，则需要设置A记录将自定义域名指向以下IP： 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 具体教程链接 Hello World于是便有了这一篇博客，以上记录的过程前前后后经过了几个星期的时间。因为太久不写文章，所以语言组织和表达能力还需要多加练习。 无论如何，总算是有了一个方便的写博客的地方，也有了第一篇博客文章。希望自己能够不断提高，写出和上面提到的dalao们一样高质量的博客文章。","link":"/2018/05/03/Hello-World/"},{"title":"Java 垃圾回收","text":"“Java 与 C++ 之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。” —— 周志明 《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 以下内容整理自周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 对象回收条件引用计数算法（Reference Counting）给对象添加一个引用计数器，每当有一个地方引用这个对象时，计数器的指加1；当引用失效时，计数器的指减1；任意时刻计数器为0的对象就是不可能再被使用的。 优点：实现简单，判定效率高 缺点：难以解决对象间循环引用问题 主流Java虚拟机均未选择引用计数算法来管理内存。 可达性分析算法（Reachability Analysis）通过一系列 GC Roots 对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连，则此对象不可用。 在Java中，可作为GC Roots的对象如下： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（一般说的Native方法）引用的对象 在主流的商用程序语言的主流实现中，都是通过可达性分析来判断对象是否存活的。 可达性分析算法对执行时间的敏感性 从GC Roots查找引用链 可作为GC Roots的节点主要在全局性的引用与执行上下文中 如果逐个检查这里面的引用会消耗很多时间 GC停顿 分析工作必须在一个能确保一致性的“快照”中进行 GC进行时必须停顿所有Java执行线程（Sun将其称之为“ Stop The World ”） 关于引用在JDK1.2前，Java中引用的定义为：如果reference类型的数据中存储的数值代表的是另一块内存的起始地址，就称这块内存代表着一个引用。 这样的定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用和没有被引用两种状态。无法描述一些“食之无味，弃之可惜”的对象。 在JDK1.2后，Java对引用的概念进行了扩充，将引用分为以下四种，这四种引用强度依次减弱。 强引用 Strong Reference 程序代码中普遍存在的引用 被引用的对象永远不会被垃圾收集器回收 软引用 Soft Reference 有用但非必需的对象 在系统将要发生内存溢出异常之前会把其关联对象列入回收范围之内进行第二次回收 弱引用 Weak Reference 被弱引用关联的对象只能生存到下一次垃圾收集发生之前 虚引用 Phantom Reference 不会对对象的生存时间构成影响 设置的唯一目的是能在对象被回收时收到系统通知 垃圾收集算法垃圾收集算法的实现涉及大量程序细节，且各个平台虚拟机操作内存的方法各不相同，因此以下整理的仅为几种算法的主要思想，并不关注其具体实现。 标记-清除算法（Mark-Sweep）标记－清除算法是最基础的收集算法，之所以说是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。该算法分为“标记”和“清除”两个阶段。 标记：标记出所有需要回收的对象 清除：在标记完成后统一回收所有被标记的对象 该算法的不足之处： 效率问题：标记和清除两个过程的效率都不高 空间问题：标记清除后会产生大量不连续的内存碎片 复制算法（Copying）复制算法的出现是为了解决效率问题。它的大体思路为：将可用内存按容量分为大小相等的两块，每次只使用其中一块。当一块的内存用完了，就将还存活着的对象复制到另一块上，然后把已使用过的内存空间一次清理掉。 优点：每次仅对半区进行回收，按顺序分配内存即可，实现简单，运行高效 缺点：将内存缩小为了原来的一半，代价巨大 现在的商业虚拟机都采用这种收集算法来回收新生代。 研究表明，新生代中的对象98%是“朝生夕死”的，所以不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1。 在回收时，将Eden和Survivor中还存活着的对象一次性复制到另一块Survivor空间上，最后清理掉Eden和刚刚使用的Survivor空间。如果Survivor空间不够用，则需要依赖老年代内存进行分配担保（Handle Promotion）。 标记-整理算法（Mark-Compact）复制算法一般不能用于老年代，原因如下： 老年代对象存活率较高，需要进行较多复制操作，降低效率 为了不浪费50%的空间，需要额外空间进行分配担保，以应对对象100%存活的极端情况 “标记－整理”算法考虑到老年代的特点，其中标记过程与“标记－清除”算法相同，但后续步骤是让所有对象向一端移动，然后直接在清理掉端边界以外的内存。 分代收集算法（Generational Collection）当前商业虚拟机的垃圾收集都采用“分代收集”算法。 思想：把Java堆分为新生代和老年代，这样可以根据各个年代的特点采取适当的收集算法。 注：Minor GC 与 Full GC Minor GC 发生在新生代的垃圾收集动作 非常频繁，回收速度较快 Full GC / Major GC 发生在老年代的GC 经常会伴随至少一次的Minor GC 速度一般会比Minor GC慢10倍以上 垃圾收集器垃圾收集器是内存回收的具体实现。Java虚拟机规范中对垃圾收集器如何实现没有任何规定，因此不同厂商、版本的虚拟机提供的垃圾收集器区别很大。 以下收集器基于JDK1.7 Update 14后的HotSpot虚拟机。这个虚拟机包含的所有收集器如下图所示。 Serial 收集器 单线程收集器 简单高效 没有线程交互的开销，可以获得最高的单线程收集效率 最基本、发展历史最悠久 在JDK1.3.1之前是虚拟机新生代收集的唯一选择 目前为止依然是虚拟机运行在Client模式下的默认新生代收集器 ParNew 收集器ParNew收集器是Serial收集器的多线程版本。在实现上，这两者也共用了相当多的代码。 ParNew收集器是运行在Server模式下的虚拟机中首选的新生代收集器 ，一个与性能无关的重要原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 Parallel Scavenge 收集器Parallel Scavenge 收集器是使用复制算法、并行的多线程新生代收集器。 与ParNew收集器的不同之处： 关注点——吞吐量（Throughput） 吞吐量：CPU用于运行用户代码的时间与CPU总消耗时间的比值 吞吐量 ＝ 运行用户代码时间 / (运行用户代码时间＋垃圾收集时间) 高吞吐量意味着可以高效率地利用CPU时间，尽快完成运算任务 适合在后台运算不需要太多交互的任务 CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验 GC自适应调节策略（GC Ergonomics） 提供参数 -XX:+UseAdaptiveSizePolicy MaxGCPauseMillis参数更关注最大停顿时间 GCTimeRatio参数更关注吞吐量 参数打开后虚拟机会根据当前系统运行情况动态调整参数以提供最合适的停顿时间或最大吞吐量 Serial Old 收集器Serial Old 是 Serial 收集器的老年代版本。它是单线程收集器，使用“标记－整理”算法。主要意义是给Client模式下的虚拟机使用。 在Server模式下，它还有两大用途： 在JDK1.5及之前版本中与Parallel Scavenge收集器搭配使用 Parallel Scavenge 收集器架构中本身有PS MarkSweep收集器来进行老年代收集，并非直接使用Serial Old收集器，但是PS MarkSweep收集器与Serial Old的实现非常接近，所以在官方许多资料中都是都是直接以Serial Old代替PS 作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用 Parallel Old 收集器Parallel Old 自JDK1.6开始提供，是 Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。 在Parallel Old收集器出现前，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old (PS MarkSweep)收集器外别无选择。但老年代Serial Old收集器无法充分利用多CPU的处理能力，使用了Parallel Scavenge收集器未必能在整体应用上获得吞吐量最大化的效果。 Paralle Old收集器出现后，“吞吐量优先”收集器有了比较名副其实的应用组合（Parallel Scavenge + Parallel Old）。 CMS 收集器CMS (Cocurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器。 CMS收集器基于“标记－清除”算法实现，整个过程分为以下4个步骤： 初始标记（ CMS initial mark ） 标记GC Roots能直接关联到的对象，速度较快 并发标记（ CMS concurrent mark ） GC Roots Tracing的过程 重新标记（ CMS remark ） 修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录 停顿时间比初始标记阶段稍长，远比并发标记时间短 并发清除（ CMS concurrent sweep ） CMS收集器运行示意图 整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以和用户线程一起工作。 优点 并发收集。从整体上说，CMS收集器内存回收过程是与用户线程一起并发执行的 低停顿 缺点 对CPU资源非常敏感 在并发阶段，会因为占用了一部分CPU资源导致应用程序变慢，总吞吐量降低 当CPU数量较少时，CMS对用户程序的影响可能很大 无法处理浮动垃圾（Floating Garbage） 浮动垃圾：CMS并发清理阶段，用户线程产生的未被标记的新的垃圾 CMS无法在当次收集中处理浮动垃圾，只能留待下一次GC时再清理 可能出现“Concurrent Mode Failure”导致另一次Full GC的产生 基于“标记－清除”算法，收集结束时会产生大量空间碎片 G1 收集器G1（ Gabage-First ）是一款面向服务端应用的垃圾收集器。 与其他GC收集器相比，G1具备如下特点： 并行与并发 充分利用多CPU、多核环境下的硬件优势，缩短Stop-The-World的时间 部分其他收集器原本需要停顿Java线程执行的GC动作，G1仍然可以通过并发方式让Java程序继续执行 分代收集 不需要其他收集器配合就能独立管理整个Java堆 能够采用不同方式处理新创建对象和已经存活一段时间的对象 空间整合 从整体上看是基于“标记－整理”算法实现的收集器 从局部（两个Region之间）上看是基于“复制”算法实现的 两种算法都意味着G1运作期间不会产生内存空间碎片 可预测的停顿 降低停顿时间是G1和CMS共同的关注点 G1能建立可预测的停顿时间模型 使用G1收集器时，它将整个Java堆划分为多个大小相等的独立**区域 ( Region )**，虽然保留有新生代和老年代的概念，但它们之间不再是物理隔离的，都是一部分Region（不需要连续）的集合。 G1收集器可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。 G1收集器运作大致可划分为以下几个步骤（不计算维护Remembered Set的操作）： 初始标记 ( Initial Marking ) 标记GC Roots能直接关联到的对象 修改TAMS ( Next Top at Mark Start ) 的值，让下一阶段用户程序能在正确可用Region中创建新对象 需要停顿线程，耗时短 并发标记 ( Concurrent Marking ) 从GC Roots开始对堆中对象进行可达性分析，找出存活的对象 可与用户程序并发执行 最终标记 ( Final Marking ) 修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录 虚拟机将对象变化记录在线程Remembered Set Logs里，本阶段把其中数据合并到Remembered Set中 需要停顿线程，可并行执行 筛选回收 ( Live Data Counting and Evacuation ) 对各个Region的回收价值和成本进行排序，根据用户期望GC停顿时间制定回收计划 可以做到与用户程序并发执行，但停顿用户线程将大幅提高收集效率，而且时间用户可控 G1 收集器运行示意图","link":"/2018/05/05/Java-GC/"},{"title":"2018微软预科生面试经历","text":"原本打算大三暑假结束后再找实习，但是大部分企业只在上半年统一招收实习生，担心暑假之后没有什么好的实习可以找，而腾讯阿里都过了实习生招聘的时间。恰逢微软（苏州）进校现场招聘，于是就投了微软。 线上面试原本定的是5月22日在费彝民楼面试，微软之后又改到了5月28日。由于报名人数较多，因此在线下面试前又进行了一次线上面试。 线上面试大概经历了35分钟，比我想的要快了一些，但涉及到的内容还是挺多的。 自我介绍与项目首先是自我介绍，我大概说了一些自己的情况和擅长的领域。面试官说看我的学习成绩不错，是不是平时比较专注于学习，因为他看到我简历上项目只写到17年9月份，还问我是不是最新的简历。我提示他说我简历也有写18年的项目（回去之后就把项目改成了时间顺序）。 接下来就就是介绍一个自己写过的项目，我讲了最近个人完成的JavaEE课程项目，恰好项目部署在服务器上，就把URL发给了面试官，他看了之后表示还不错。 白板代码算法题很简单，一道链表相关的题目： 去除已排序链表中的重复元素。 当时写的代码： 1234567891011121314151617public Node removeDuplicate(Node head) { if (head == null) return head; Node p = head, next = head.next; int num = p.val; while (next != null) { if (next.val == num) { next = next.next; continue; } p.next = next; p = next; next = next.next; num = p.val; } p.next = null; return head;} 现在回过头来看其实多定义了一个num变量，可以直接替换成p.val。 写完之后面试官让我写几个测试用例，也就是几个用于测试的链表。我在写的过程中意识到一开始少了return语句前的一句p.next = null;，也就是没有处理最后一个元素（失误），及时添加了上去。 排序与复杂度下面面试官直接问我有没有学过判断算法时间复杂度，说一下几种排序算法的时间复杂度。在我说到快速排序的平均时间复杂度是O(nlogn)时，面试官让我解释一下为什么说是平均。 设计模式下面面试官让我说一下项目中用过一些设计模式。我讲了工厂模式，在项目关于对象的创建是Spring管理的。他说不用考虑具体项目，说一个印象最深的策略模式。我介绍了一下策略模式，解释了一下策略模式的优点。 ArrayList与LinkedList面试官提的问题之间似乎没有什么关联，接下来问了ArrayList和LinkedList的区别和实现机制，当我说到ArrayList会动态扩大数组时，面试官让我解释一下动态扩张数组的原理，我不确定他要问的原理有多深，而且我并没有看过ArrayList源码，因此我说对具体实现不太了解，面试官也就没有继续问下去。 LRU Cache最后面试官问了LRU Cache，让我简单实现一个LRU Cache，我表示对LRU算法有了解，但是不记得具体实现。面试官让我按自己的理解写，我先说了自己的思路，一开始想的使用队列（说完意识到不对），面试官提示用LinkedList还是ArrayList，由于涉及到频繁的删除与插入操作，当然选择了LinkedList，接下来面试官问LinkedList查找的效率，O(n)明显比不上ArrayList，我想了之后说可以用Map来简化查找过程，key是Cache中的内容，value是指向LinkedList中元素的指针。面试官表示可以，之后也没让我再写代码。 后来发现本题是LeetCode上的原题LRU-Cache，可以使插入和查找时间均为O(1)，思路很巧妙。 线上面试总结总的来说线上面试的内容还是比较简单的，毕竟只是线下面试前一轮的筛选工作，不过因为是第一次面试难免有点紧张，给自己发挥打个7分吧。 线下面试一面一面的面试官是个挺年轻的小伙子，自我介绍之后让我介绍一个的项目，我讲了花旗杯的项目。接着问了我Restful API是如何设计的，对账目的自动归类、数据库的Schema设计等细节问题，问得还是比较细的。 接下来手写算法题是： 假设二叉树的每一个节点都有一个指向父节点的指针，现在任给一个节点，找到这棵树的中序遍历中此节点的下一个节点。 简单思考了一下，分了两种情况，节点有右子树和没有右子树，顺利写完了代码。第一次写完有点小错，被面试官要求再检查一下的时候发现了错误及时改了过来。 二面二面面试官是个小姐姐，比一面感觉亲切很多。一开始同样自我介绍然后讲项目，我还是讲的花旗杯的项目，跟一面比问的问题并不是很多。小姐姐还对云计算的项目表现出了一些感兴趣，问我懂不懂Hadoop，我说不是特别了解。 二面一开始问的似乎是一道智力题： 有25匹马，5个赛道，最少要比多少次能够找出最快的5匹马？ 这题我确实想了很久，一开始给出的想法是，先分5组比5次，把每次里最快的拿出来再比一次，得出25匹马中最快的一匹，把最快的一匹马一开始所在组的第二拿出来再跟另外四匹比，得出第二快的一匹，由此类推。很容易想到的方法，但是比的次数不是最少的。 后来想可以用到排除法，经过小姐姐的提醒，前5组中最快的5匹比过之后，最慢的那匹所在组的后4匹不可能进前5，全部淘汰，同理，可以排除掉4+3+2+1=10匹马。然后小姐姐也没让我继续算下去，直接做算法题了。 找出二叉树中两个节点的最近公共父节点。 第一个想到的方法是，找出从根到这两个节点的路径，存在两个列表中，然后列表中的项两两一一比对，时间复杂度为O(n)。 一时想不出更好的方法，小姐姐就让我写了这种方法的代码。当时觉得时间已经过了挺久，所以写的时候有比较急，递归方法里写的有点乱。 本题也是Leetcode中的原题Common-Ancestor，有更好的递归解决方法。 三面三面面试官是个挺和蔼的大叔（并不是老外，松了一口气），人很好。同样的自我介绍，他直接问了项目经历里第一个JavaEE项目，问我如果管理员想查看所有在线用户该怎么做，我一开始想的是把登录状态存数据库，但由于是Web项目，显然不太合理。于是想到监控Session，用Map存储在线用户的Session，他问我Map放在哪里，让我大概写一下如何实现。我写了一个简单的接口和实现类。 三面算法第一题： 把二叉查找树中一个节点的值变为原来的2倍。 二叉查找树的问题，想了想也就是一次删除和一次插入的操作，分别写了两个方法。 三面算法第二题： 给一个m*n的矩形，每一格有一个正整数值，从左上角开始走到右下角，每一次可以向上下左右四个方向走，问走到右下角所有路径中数字和的最小值以及对应的路径。 总算不是树的问题了，一开始我以为是一道典型的动态规划题（只能向下或向右走），听了描述之后发现不对。一时没想到什么好办法，用递归回溯暴力穷举写完了。（一开始的时候只求了最小值，并没有记录路径，后来面试官说要求得出路径，于是把代码怎么改大概描述了一下）。 问了几个问题，面试官说他是志愿者，也都不太了解，于是还带我去问了HR，人确实很不错。 总结三次面试都是手写算法，而且写了三次二叉树··· 总的来说题并不变态，想不到最优解法的话，基本的方法还是能想到的，多做一做LeetCode很有好处，手写代码最好提前写一写，不然可能像我二面的时候一样这儿插一点那儿涂一点看起来很乱。","link":"/2018/05/28/microsoft-interview/"},{"title":"2018清华软院推免经历","text":"2018年9月28日，我接受了清华大学的待录取通知，两个多月的保研奔波也最终尘埃落定。保研的过程对我来说真的是一波三折，好在最后还是得到了一个满意的结果。 机试清华推免机试语言统一使用C++，电脑环境为Windows，会预装 CLion 和 Visual Studio，并提前创建好了项目，考试时仅需在题目对应项目下的cpp文件中编写代码即可。 机试考试时间为3小时，试题一共3道，题目会打印在纸上发给大家，整个机试体验总体还是不错的。 日历转换 有一种不同的历法，它的一天和目前历法中一天的长度相同，每天有10个小时，每小时100分钟，每分钟100秒，同时一年有10个月，一个月有10个星期，一个星期有10天，现在需要把当前历法中的时间转换为这种历法中的时间。规定当前历法的开始时间为2000-1-1 0:0:0，对应新历法中的0-1-1 0:0:0，秒数向下取整，需要考虑闰年。输入：当前历法的某时刻输出：对应新历法的时刻 第一题送分，但是一开始没注意题目中一天的时间相同，所以一开始结果和给的用例一直对不上，导致浪费了不少时间。 麦森数 形如2p-1的素数被称为麦森数，这时p也一定是个素数，但反过来不一定，即如果p是个素数，2p-1不一定也是素数。到1998年底，人们已经找到了37个麦森数，最大的是p=3021377，它有909526位。输入p (1000 &lt; p &lt; 3100000)，计算2p-1的位数和最后500位数字。 快速幂+大数乘法，只用处理最后500位的乘法，数的位数为 [p*lg2] + 1。 打气球LeetCode原题：312. Burst Balloons 考完才知道是LeetCode上的原题，动态规划，考试时时间不够没想到递推式，还是怪自己刷题不够多··· 面试面试安排在笔试后第二天上午，一共六十多人，分成了五个教室，我在的教室有五个老师和一个助教，助教会帮忙给老师发简历以及记录面试过程。 首先是自我介绍，同时老师会查看简历。老师会轮流问问题，主要是有关简历上的项目，以及一些基础知识（老师会看着成绩单和简历问问题）。问题包括： 你的项目中用到了Hadoop，性能如何？ 项目名称中的“智能“体现在哪里？ 推荐系统是如何实现的？ 你们处理的数据量并不算大，为什么要用Hadoop？ 你说对网络比较感兴趣，网络包括几层，有哪些协议？ 解释编译原理中的自动机、上下文无关文法。 （英文）解释快速排序。 （英文）快速排序中基准如何选取？ 你的项目名中大多包含“智能”两个字，你对智能有什么看法？ 面试过程中有老师根据简历上的链接访问了我的个人网站，看到我的微软面试经历就问了我在微软做了些什么，看了我的Github主页，让我介绍了几个pin的仓库。 总的来说面试的过程还算比较轻松，全程都处在一种聊天的氛围中。回答总的还算顺畅，除了被问到编译原理概念时有点记不清了，感觉问问题的老师有些不太满意··· 总结总结下来，机试题整体难度不算大，但也需要一定的刷题量，搞过ACM的同学机试应该很占优势，机试时也有大佬提前交卷，面试问的问题其实都很基础，老师会问你考的比较好的科目的问题，不会刻意为难你。","link":"/2018/09/28/tsinghua-university/"},{"title":"LeetCode 2019 秋季编程大赛总结","text":"2019 力扣杯全国秋季编程大赛 算是我大学以来第一次参加的算法编程比赛。由于并没有接触过算法竞赛方面的知识，总体感觉是五道题难度跨越特别大，前三题花了不到半个小时，后面的时间几乎都用在最后一题上。 题解1. 猜数字 小A 和 小B 在玩猜数字。小B 每次从 1, 2, 3 中随机选择一个，小A 每次也从 1, 2, 3 中选择一个猜。他们一共进行三次这个游戏，请返回 小A 猜对了几次？ 输入的guess数组为 小A 每次的猜测，answer数组为 小B 每次的选择。guess和answer的长度都等于3。 送分题，代码如下： 123456789class Solution { public int game(int[] guess, int[] answer) { int res = 0; for (int i = 0; i &lt; 3; i++) if (guess[i] == answer[i]) res++; return res; }} 2. 分式化简 化简如下分式： $$a_0+\\frac{1}{a_1+\\frac{1}{a_2+\\frac{1}{\\cdots}}}$$ 输入的cont代表连分数的系数（cont[0]代表上式的a0，以此类推）。返回一个长度为2的数组[n, m]，使得连分数的值等于n / m，且n, m最大公约数为1。 模拟题，从最里面的分式开始计算，题目中说明了cont[i] &gt;= 0，因此不用考虑负数情况（当时在比赛时没有注意这一点，因此为考虑负数多花了些时间），最后分子分母同时除以最大公因数。 12345678910111213141516171819class Solution { private int gcd(int a, int b) { return b == 0 ? a : gcd(b, a % b); } public int[] fraction(int[] cont) { int up = 1, down = cont[cont.length - 1]; for (int i = cont.length - 2; i &gt;= 0; i--) { int a = cont[i]; up += a * down; int tmp = up; up = down; down = tmp; } int gcd = gcd(up, down); return new int[]{down / gcd, up / gcd}; }} 3. 机器人大冒险 力扣团队买了一个可编程机器人，机器人初始位置在原点(0, 0)。小伙伴事先给机器人输入一串指令command，机器人就会无限循环这条指令的步骤进行移动。指令有两种： U: 向y轴正方向移动一格 R: 向x轴正方向移动一格。 不幸的是，在 xy 平面上还有一些障碍物，他们的坐标用obstacles表示。机器人一旦碰到障碍物就会被损毁。 给定终点坐标(x, y)，返回机器人能否完好地到达终点。如果能，返回true；否则返回false。 模拟题，机器人若能走到终点，那么需要的指令数一定恰好等于 x+y，模拟 x+y 次后判断是否处于终点位置，如果中途遇到障碍或者走出 (x, y) 范围则提前结束。 一开始将所有障碍坐标保存在 Map 中，用于加速判断当前坐标是否处在障碍上。 比赛中的一次罚时是因为最后直接 return true 没有判断是否位于终点… 做简单题也一定要细心不能大意。 1234567891011121314151617181920212223242526class Solution { public boolean robot(String command, int[][] obstacles, int x, int y) { Map&lt;Integer, Set&lt;Integer&gt;&gt; obsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; obstacles.length; i++) { int x1 = obstacles[i][0]; int y1 = obstacles[i][1]; if (!obsMap.containsKey(x1)) { obsMap.put(x1, new HashSet&lt;&gt;()); } obsMap.get(x1).add(y1); } int curX = 0, curY = 0; for (int i = 1; i &lt;= x + y; i++) { char step = command.charAt((i - 1) % command.length()); if (step == 'U') curY += 1; else curX += 1; if (obsMap.containsKey(curX) &amp;&amp; obsMap.get(curX).contains(curY)) return false; if (curX &gt; x || curY &gt; y) return false; } return curX == x &amp;&amp; curY == y; }} 4. 覆盖 你有一块棋盘，棋盘上有一些格子已经坏掉了。你还有无穷块大小为1 * 2的多米诺骨牌，你想把这些骨牌不重叠地覆盖在完好的格子上，请找出你最多能在棋盘上放多少块骨牌？这些骨牌可以横着或者竖着放。 输入：n, m代表棋盘的大小；broken是一个b * 2的二维数组，其中每个元素代表棋盘上每一个坏掉的格子的位置。 输出：一个整数，代表最多能在棋盘上放的骨牌数。 限制： 1 &lt;= n &lt;= 8 1 &lt;= m &lt;= 8 0 &lt;= b &lt;= n * m 这题在比赛时并没有什么思路，后来看题解可以用状态压缩DP或者二分图匹配来做，二分图匹配的方法很巧妙，之后有空会把代码补上。 5. 发 LeetCoin题目描述很长，可以看此链接。 大意是说有一棵树（不一定是二叉树），树上的每个节点代表一个员工，树的层次就代表上下属关系。现在可以进行三种操作： 给某个节点（员工）发一定数量硬币。 给某棵子树的所有节点都发一定数量硬币。 查询某棵子树所有节点的硬币之和。 程序需要尽可能高效地完成这三种操作。 在执行具体操作前，我建立的数据结构包括： all 数组：来记录每个节点的硬币数，初始均为0 father 数组：记录每个节点的父节点编号（类似并查集中的数组） sons Map：记录每个节点的所有直接子节点集合 totalSons 数组：记录以每个节点为根的子树一共有多少节点。这里会用 countSons() 函数递归计算。 当执行操作1时，步骤如下： 将 all 中对应节点硬币数增加； 在 all 数组中依次更新当前节点父节点的硬币数，直到到达根节点，这里会用到 father 数组。 当执行操作2时，步骤如下： 使用 update() 函数递归更新当前节点子树中所有节点硬币数，在更新时，使用 totalSons 数组可以直接计算出当前节点硬币数应该增加多少。 与操作1类似，依次更新父节点硬币数，不过这里更新时增加的值（addFatherCoin）与1中有所不同。 具体实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Solution { private int countSons(int k, Map&lt;Integer, Set&lt;Integer&gt;&gt; sons) { if (!sons.containsKey(k) || sons.get(k) == null || sons.get(k).isEmpty()) return 0; Set&lt;Integer&gt; sonSet = sons.get(k); int res = sonSet.size(); for (Integer son : sonSet) { res += countSons(son, sons); } return res; } private void update(int num, int coin, int[] totalSons, int[] all, Map&lt;Integer, Set&lt;Integer&gt;&gt; sons) { all[num] = (all[num] + coin) % 1000000007; if (totalSons[num] == 0) return; all[num] = (all[num] + totalSons[num] * coin % 1000000007); for (int son : sons.get(num)) { update(son, coin, totalSons, all, sons); } } public int[] bonus(int n, int[][] leadership, int[][] operations) { int[] all = new int[n + 1]; int[] father = new int[n + 1]; Map&lt;Integer, Set&lt;Integer&gt;&gt; sons = new HashMap&lt;&gt;(); father[1] = -1; for (int i = 0; i &lt; leadership.length; i++) { int a = leadership[i][0]; int b = leadership[i][1]; father[b] = a; if (!sons.containsKey(a)) sons.put(a, new HashSet&lt;&gt;()); sons.get(a).add(b); } int[] totalSons = new int[n + 1]; for (int i = 0; i &lt; n; i++) { totalSons[i + 1] = countSons(i + 1, sons); } List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; operations.length; i++) { int op = operations[i][0]; int num = operations[i][1]; if (op == 1) { int coin = operations[i][2]; all[num] = (all[num] + coin) % 1000000007; int cur = father[num]; while (cur != -1) { all[cur] = (all[cur] + coin) % 1000000007; cur = father[cur]; } } else if (op == 2) { int coin = operations[i][2]; update(num, coin, totalSons, all, sons); int addFatherCoin = coin * (totalSons[num] + 1) % 1000000007; int cur = father[num]; while (cur != -1) { all[cur] = (all[cur] + addFatherCoin) % 1000000007; cur = father[cur]; } } else { res.add(all[num]); } } int[] resArr = new int[res.size()]; for (int i = 0; i &lt; res.size(); i++) resArr[i] = res.get(i); return resArr; }} 后续可能由于这次是 LeetCode 第一次举办的全国大赛所以大佬们并没有关注的原因，我最后竟然正好是第50名（能拿到奖品的最后一名） 。 第 1 名选手获得《计算机程序设计艺术》卷 1 - 卷 4A ；第 2-5 名选手，优先随机挑选以下图书，第 6-50 再做选择，数量有限，先选先得，图书包含：《程序员面试金典 · 第六版》、《算法 4》、《挑战程序设计 2》、《Python 深度学习》、《C++ Primer中文版（第5版）》、《Python机器学习手册：从数据预处理到深度学习》、《Effective C++：改善程序与设计的55个具体做法（第三版）》、《Python编程之美：最佳实践指南》、《Code：隐匿在计算机软硬件背后的语言（英文版）》。 虽然只剩下最后两本书可以选了，不过还是挺开心的。选了一本《程序员面试金典》，很快就收到了书，厚厚的一大本，之后找工作的时候有东西看了~","link":"/2019/10/14/leetcode-autumn-contest/"},{"title":"kdevtmpfsi 进程占用 CPU 问题","text":"今天用实验室电脑（Arch Linux 系统）训练模型时发现训练一个 epoch 的时间比往常要慢得多。使用top指令发现有名为 kdevtmpfsi 的进程 CPU 占用率达到 500%，且直接使用 kill -9 pid 杀死后还会重复出现。 12 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 619970 huangxi+ 20 0 3025392 2.3g 2712 S 582.4 14.8 47:36.78 kdevtmpfsi 问题排查根据网上资料[1]显示，kdevtmpfsi 进程为挖矿程序。 通过 ps -ef | grep kdevtmpfsi 可以获知该进程的 pid，然而在用 kill -9 pid 杀死进程后不久又会重新出现，因此必然是有另一个程序会不断重新启动该进程。 查看定时任务根据分析，有可能是恶意程序在 Linux 中注册了定时任务。查看 Cron Arch wiki 得知，Arch 中默认使用 systemd/Timers 管理定时任务。 通过 systemctl list-timers 查看所有启动的定时任务，输出如下： 1234567NEXT LEFT LAST PASSED UNIT ACTIVATES Sun 2020-10-18 00:00:00 CST 6h left Sat 2020-10-17 00:00:46 CST 17h ago man-db.timer man-db.service Sun 2020-10-18 00:00:00 CST 6h left Sat 2020-10-17 00:00:46 CST 17h ago shadow.timer shadow.service Sun 2020-10-18 14:03:53 CST 20h left Sat 2020-10-17 14:03:53 CST 3h 44min ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service3 timers listed.Pass --all to see loaded but inactive timers, too. 并没有发现异常的定时任务。 守护进程由此可以怀疑是有守护进程在不断重启 kdevtmpfsi 进程。使用 systemctl status pid （pid 为 kdevtmpfsi 进程id）查看后发现， /var/tmp/kinsing 与 /tmp/kdevtmpfsi 进程处于同一 CGroup 中。 分别使用 kill -9 杀死这两个进程并删除系统中对应的文件，之后 kdevtmpfsi 进程就不会再次出现了。 原因分析从网络上资料来看，基本上都是服务器遭受了该进程的影响，而我的环境是实验室里的PC机，并且并没有打开 sshd 服务。 之后分析发现，被攻击的原因很可能是我在电脑上开了一晚上的 Flink 本地集群。在[3]的其中一个回答中也表示是在启动了 Flink 集群后遇到了这个问题。Flink 集群启动后默认会在 8081 端口部署 web UI，通过 web UI 可以提交用户自定义 Job 在集群中执行。因此攻击者应该是通过 Flink web UI 暴露的端口实施了攻击。 通过查看 Flink standalonesession 的 log，发现的确在凌晨有记录一些异常信息： flink-huangxiao-standalonesession-0-huangxiao-lab.log >folded12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697982020-10-17 00:09:40,372 WARN org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint [] - Unhandled exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 00:09:41,896 ERROR org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler [] - Caught exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 03:17:44,446 WARN org.apache.flink.runtime.webmonitor.handlers.JarRunHandler [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.2020-10-17 03:17:44,464 INFO org.apache.flink.client.ClientUtils [] - Starting program (detached: true)2020-10-17 03:17:44,486 ERROR org.apache.flink.runtime.webmonitor.handlers.JarRunHandler [] - Exception occurred in REST handler: No jobs included in application.2020-10-17 06:26:13,712 WARN org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint [] - Unhandled exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 06:26:15,227 ERROR org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler [] - Caught exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 16:47:29,283 WARN org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint [] - Unhandled exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?] 所以说，不管是在个人 PC 还是服务器上部署 Flink 集群后，都是很有可能受到攻击的，需要提前做好准备和防御的措施。 参考资料 [1] https://bbs.huaweicloud.com/blogs/149758[2] https://blog.csdn.net/u014589116/article/details/103705690[3] https://stackoverflow.com/questions/60151640/kdevtmpfsi-using-the-entire-cpu","link":"/2020/10/17/kdevtmpfsi/"},{"title":"博客主题切换 TeXt -&gt; icarus","text":"这两天将博客风格从 TeXt 切换到了 icarus。切换的原因主要是因为 TeXt 的作者有很长一段时间没有更新了，所以最新的 release 版本存在的 bug 一直无法得到解决。 同时。随着主题更换，博客框架也从 Jekyll 切换到了 Hexo。 Hexo 使用Hexo 是基于 Node.js 的博客框架，其官方文档整体感觉比 Jekyll 要友好许多，对中文也有很好的支持。 Hexo 命令 也都比较简单好用，这里可能会用得比较多的有： hexo clean：清除缓存和已生成的静态文件 hexo generate：生成静态文件 hexo server：启动本地服务器，本地端口为4000 hexo deploy：部署网站 icarus 主题icarus 主题 是我在 Github 上搜索后发现星标比较多的一个主题，整体感觉非常清爽，同时能够展示的信息也应有尽有。icarus 的文档是通过其示例页面以博客的形式给出的，内容也十分详细，且同时包含了中英文。 这里仅仅记录一些我认为比较有用的配置项： 代码折叠在 markdown 文件中，使用如下语法来折叠代码块： 123{% codeblock &quot;可选文件名&quot; lang:代码语言 &gt;folded %}...code block content...{% endcodeblock %} 侧边栏位置固定在 _config.icarus.yml 中配置： 12345sidebar: left: sticky: false right: sticky: true 此配置会对全局生效，如果仅仅想对具体文章的页面配置，需要创建 _config.post.yml 文件并在其中配置，一般来说会将目录项所在侧边栏固定。 博客文章显示 toc需要在每篇博客的 format-matter 中添加 toc: true 数学公式显示需要在 _config.icarus.yml 中开启插件： 12plugins: mathjax: true 页面布局宽度配置 页面宽度定义样式文件：&lt;icarus_directory&gt;/include/style/responsive.styl 挂件定义文件：&lt;icarus_directory&gt;/layout/common/widgets.jsx 主内容定义文件：&lt;icarus_directory&gt;/layout/layout.jsx 通过修改 CSS 类名中的数字改变挂件或主内容占据的栏数。数字后的屏幕尺寸，如tablet和widescreen，指代着栏数量生效的屏幕尺寸条件。 修改类名中的数字使主内容栏的栏数量和所有挂件栏的栏数量在相同屏幕尺寸下相加等于12。 从 Jekyll 切换到 Hexo这里在 Hexo 文档中也有描述，需要将原 _post 目录中的所有文件复制到 source/_posts 目录中，并且在 _config.yml 中修改 new_post_name 参数： 1new_post_name: :year-:month-:day-:title.md 在这之后还需要将原博客中存储的图片复制到 source 目录下，同时注意修改博客内容中对图片的引用路径。 随着主题的切换，在原先主题的 markdown 文件中的一些语法可能在新的主题下并不生效（比如原来主题对 emoji 的支持），需要将博客内容再做一遍检查。 博客部署Github Page 不提供对 Hexo 的原生支持，因此我们要手动将 hexo 生成的静态页面部署到 Github 仓库中。这里我尝试使用了 Github Actions 提供的自动部署功能，但是并没有生效… 所以目前还是用的手动部署的方法。 博客源代码我放在 source 分支下，生成的静态页面放在 master 分支。 这里需要安装 hexo-deployer-git 1$ npm install hexo-deployer-git --save 同时修改 _config.yml 中内容： 1234deploy: type: git repo: &lt;repository url&gt; branch: master 之后每次更新内容后，通过 hexo clean &amp;&amp; hexo deploy 就可以将最近静态文件部署到 master 分支。 关于 Github Action 以及目前没能生效的原因，如果之后有时间的话会研究一下~","link":"/2020/10/19/icarus-theme/"},{"title":"《Streaming Systems》Preface 前言","text":"《Streaming Systems》一书在网上得到了一致的好评与推荐，我最近也刚开始读。该书目前还没有中文翻译版本，我打算按照书中章节的顺序，对每章的内容进行相关整理，方便后续的总结与回顾。因为有很多名词可能暂时无法准确地翻译成中文，因此在整理过程中可能会出现很多中英文夹杂的情况。希望读完这本书后可以对流处理的设计、发展和存在的关键问题等方面有一个更高以及更深层次的认识。 前言部分主要介绍了本书的三位作者以及他们各自撰写的章节、阅读指导、本书希望能够带给读者带来的收获以及一些可获得的资源。 一个有趣的地方是，作者特地提到他们本来要求动物书的封面上是一只机器恐龙，但是O’Reilly认为它不能很好地转化为线条艺术，虽然作者并不同意这个看法，但最后还是选择了一条鲑鱼作为妥协，也就是现在封面上所能看到的那只。以下内容是对书中部分前言内容的翻译（由于尚未读完，因此一些内容表述可能有误，尤其是章节内容的概括部分，后续阅读完相关章节及全部内容后会修改为更加准确的表述）： 阅读指导这本书在概念上主要分为两个部分，每个部分都有四个章节，这两部分的四个章节后都各自有着一个相对独立的章节。 第一部分 The Beam Model （第一章到第四章），主要介绍了为 Google Cloud Dataflow 所开发的高层批加流数据处理模型，它后来作为 Apache Beam 这个项目捐赠给了 Apache 软件基金会。这部分由以下四个章节组成： 第一章，Streaming 101，介绍了流处理的基础概念，建立了一些术语，讨论了流处理系统的能力，区分了两种重要的时间概念（处理时间和事件时间），最后讨论了一些通用的数据处理模式。 第二章，回答了关于数据处理的 What, Where, When 和 How 这四个问题，这些问题涵盖了针对无序数据的可靠流处理中的核心概念细节。 第三章，Watermarks（水位线），深度考察了时间过程的相关指标、水位线是如何创建的以及如何在 pipeline 中传播的。最后考察了两个真实世界中水位线的实现细节。 第四章，Advanced Windowing（高级窗口），讨论一些高级的窗口和触发器概念，比如处理时间窗口，会话和自定义触发器。 在第一部分和第二部分之间，第五章介绍了 Exactly-Once 和 Side Effects，这一章中作者列举了实现端到端 exactly-once (or effectively-once) 处理语义所存在的挑战，介绍了三种不同的实现 exactly-once处理语义方法的实现细节，分别是：Apache Flink，Apache Spark 和 Google Cloud Dataflow。 第二部分，Streams and Tables（第六章到第九章），从概念上研究了从底层上思考流处理的两种方式：流和表。这部分同样包括四个章节： 第六章，Streams and Tables，介绍了流和表的基本概念，透过流和表的视角分析传统的 MapReduce 方法，并且建立了流和表的一般性理论，可以囊括Beam Model中的所有内容。 第七章，The Practicalities of Persistent State（持久化状态实践），考察两种一般类型的状态，并且分析一个实际用例，以了解一般状态管理机制的必要特征。 第八章，Streaming SQL，研究了在关系代数和SQL的语义下流处理的含义，对比了在 Beam Model 和传统 SQL 中的固有的流和表的概念。 第九章，Streaming Joins，研究了一系列不同的join类型，分析它们在流的上下文中的行为。 最后，第十章 The Evolution of Large-Scale Data Processing，浏览了 MapReduce 一族数据处理系统的重要历史，考察了一些重要的贡献，这些贡献使得流处理系统演变成了今天的样子。 带给读者的收获 你可以从本书中学到的最重要的一点是流和表的理论以及它们是如何相互关联的，其他的一切都建立在此之上。从第六章开始会接触到这一话题。 时变关系是一种启示。 它们是流处理的体现：流系统被构建出来所希望实现的一切、以及与我们在批处理世界中都知道和喜爱的熟悉工具的强大连接的体现。 从第八章开始会学习到这一点。 一个实现良好的分布式流处理引擎是一种魔法。这可以说适用于一般的分布式系统，但是随着您更多地了解这些系统是如何构建以提供它们所做的语义的（从第三章到第五章中的案例），就会更加明显地看到它们为你做了多少繁重的工作。 LaTeX/Tikz 是一个制作图表和动画的神奇工具，希望书中在讨论复杂话题时所展示出来的清晰的动画图表可以让更多人去尝试使用 LaTeX/Tikz。 线上资源图片图片在线网址：http://www.streamingbook.net/figures 。 动画图片是通过首先用 LaTeX/Tikz 绘图，渲染成 PDF，再通过 ImageMagick 转成动画 GIF 制作的。绘制动画的完整源代码和说明可以在GitHub上找到：http://github.com/takidau/animations 。但请注意这大约有14000行 LaTeX/Tikz 代码，它们并没有考虑到可能被其他人阅读和使用。 代码尽管书的内容大部分是概念性的，但是仍然使用了一些代码和伪代码片段来帮助阐明要点。代码可以在线获取：http://github.com/takidau/streamingbook 。 由于理解语义是主要目的，代码主要是以 Beam 的 PTransform/DoFn 实现提供的，并附带有单元测试。","link":"/2021/12/06/streaming-systems-preface/"},{"title":"《Streaming Systems》第一章 Streaming 101","text":"Streaming 101 的标题来自于作者曾经发表的两篇博客文章：”Streaming 101“ 和 “Streaming 102”。 第一章包括了对流处理中基本概念的描述，讨论了流式系统的能力、两种重要的时间概念，以及一些常见的数据处理模式。 流式数据处理是如今大数据中的一大重要话题，理由有以下几点： 企业希望能够更及时地了解和洞悉他们的数据，切换到流式处理是降低延迟的一个很好的方法 使用专为此类永无止境的大量数据设计的系统，可以更容易地控制在现代企业中越来越普遍的海量、无界数据集 当数据到达时进行处理可以使工作量在时间上的分布更加均匀，从而可以提供更加一致和可预测的资源消耗量 术语：什么是流？对于流进行准确定义的一大难题在于：很多事物都应该被描述为它们是什么，但它们最终被俗称为在历史上是如何被实现的（即流处理引擎）。术语上准确性的缺失导致了在某些情况下，流式系统的能力被错误地限制成在历史上被描述为“流”的系统所具备的能力，比如只能产生用于估计或预测性的结果。 考虑到经过良好设计的流式系统具有和批处理系统一样产生正确、一致、可重复结果的能力，这里我们更倾向于将术语“流”设定为一个非常具体的含义： 流式系统：一种在设计时考虑到无界数据集的数据处理引擎。 准确的术语在讨论不同类型的数据时也大有益处，从作者角度来看，有两个重要且正交的维度来定义一个给定的数据集：cardinality（基数） 和 constitution（结构）。 Cardinality 描述了数据集的规模。对于描述粗粒度的 cardinality，有两种不同的数据集：有界数据 和 无界数据。 Constitution 描述了数据的物理表现形式。constitution 定义了问题中跟数据交互的方式，简单来说，有两种主要的 constitution：Table 和 Stream。 缺陷被过分夸大的流式系统在历史上，流式系统一度被贬低为只能提供低延迟、不准确或是预测性的结果，通常跟一个能力更强并能提供最终准确结果的批处理系统结合在一起，也就是通常说的Lambda架构。 Lambda 架构的维护是一大难题，你需要构建、准备和维护两套独立的 pipeline，并且最终要以某种方式将两套 pipeline 的结果合并到一起。 随着之后数年在强一致性流式引擎上的研究，Lambda 架构逐渐不再有吸引力。Jay Kreps 发表了《Questioning the Lambda Architecture》的博文，他解决了在使用像 Kafka 这样的可重放系统与流式系统连接背景下的可重复性问题，并且提出了 Kappa 架构，基本含义为使用适合当前作业的且经过精心设计的系统只运行单个 pipeline。 这里，作者希望更进一步，他认为经过精心设计的流式系统实际上提供了批处理功能的严格超集。取模的结果可能是效率上的提升，我们不再需要如今还存在着的批处理系统。感谢 Apache Flink 社区的人们将这个想法铭记于心，并构建了一个即使在批处理模式下也在幕后全程进行着流式处理的系统。 其实，为了能够击败批处理系统，只需要做到两点： 1. 正确性（Correctness） 这使你可以与批处理并驾齐驱。正确性可以归结为一致性存储。流式系统需要有能够随着时间推移持久化 checkpoint 状态的方法。考虑到机器故障，这需要精心的设计来保证一致性。再次重申非常重要的一点：正确性需要 exactly-once 处理语义，exactly-once 处理语义需要强一致性。 2. 推断时间的工具（Tools for reasoning about time） 这使你可以超越批处理。推断时间的工具对于处理无界无序且处理时间偏差不断变化的数据是必不可少的。 事件时间 vs 处理时间在任何数据处理系统中，一般都有两种我们所关心的时间： 事件时间 Event time：事件真实发生时的时间 处理时间 Processing time：事件被在系统中被观察到的时间 不是所有的案例都关心事件时间，但绝大多数都会。在理想情况下，事件时间和处理时间应该总是相等的，事件在发生时就立刻被处理。但在真实世界中，事件时间和处理时间之间的偏差不仅是非零的，而且是关于输入源、执行引擎和硬件特征相关的高度可变的函数。影响事件时间和处理时间之间偏差级别的因素包括以下几点： 共享资源的限制，如网络拥塞，网络分区，或在非专用环境中的CPU共享 软件原因，如分布式系统逻辑、竞争等 数据自身的特征，比如键值分布，吞吐量变化，或其他无法预知的变化（如飞机乘客在整个航班飞行过程中离线使用手机后退出飞行模式） 结果是，如果将真实世界中事件时间和处理时间之间的过程关系画到图中，可能如下图所示： 数据处理模式有界数据处理有界数据在概念上非常直接，在下图中，我们在左图数据集上运行数据处理引擎，比如 MapReduce，得到右图中具有新结构且有更多内在价值的数据集。 无界数据：批处理批处理引擎虽然在设计时没有显式考虑无界数据，但从批处理系统被构思出来以来，它们也可以用于处理无界数据集。处理方法无非是将无界数据切割成适合批处理的有界数据集合。 固定窗口最常见的方式，将输入数据划分到固定大小的窗口，再分别处理这些有界的窗口，如下图所示。 但实际上，大部分系统仍然需要解决完整性（completeness）的问题（考虑到网络问题，事件写入日志可能会有延迟，事件可能来自移动设备等等），这意味一些缓解措施可能是必要的，比如推迟处理过程直到确认所有数据都已经被收集到，或者在数据延迟到达时重新处理整个批中的数据等。 会话会话一般被定义为一段时间内的活动，当一段时间不出现活动时即终止。当用传统批处理引擎计算会话时，总是会出现会话被分割到不同 batch 中的情况，如下图中的红色标记所示。我们可以通过增加 batch size 的方式来减少这种情况，但代价是会增大延迟。另一种选择是通过增加额外的逻辑来拼接会话，但代价是使问题变得更加复杂。 无界数据：流处理相比于基于批的方式处理无界数据的方法，流式系统是转为无界数据而设计的。对于许多现实世界中的分布式输入源，数据不仅仅是无限的，同时还有如下特点： 在事件时间上高度无序 不断变化的事件时间偏差 对于处理具有这些特征的数据，方法大致可以分为四类：不考虑时间（Time-agnostic）、近似估计（Approximation algorithms）、根据处理时间划分窗口以及根据事件时间划分窗口。 不考虑时间该方法被用来处理时间无关紧要的场景，所有相关逻辑都是数据驱动的。批处理系统同样适用于该场景。具体案例有： 过滤 Inner joins 内连接 当将两个无界数据源做内连接时，如果结果仅仅关心同时从两个源中到达的元素，那么这里的逻辑并不包含时间元素。只需要将某一边数据缓存到持久化状态中，当另一边也出现该数据后发送 join 结果即可。（实际上，这里可能需要一些垃圾收集策略，这可能会是基于时间的） 但如果将语义切换到外连接，那么就会引入数据完整性的问题：看到某一边的某个数据之后，如何知道另一边会不会再次出现这条数据？实际情况是无法判断，所以这里需要引入超时概念，也就引入了时间元素。 近似估算算法第二大类方法是估算算法，比如估算 Top-N，流式 k-means 等等。这些算法以无界数据为输入，输出近似希望得到的结果。 估算算法的优势是低开销，且适用于无界数据；劣势是只适用于很少的情况，并且算法本身非常复杂。 值得注意的是这些算法在设计中通常是有时间元素的，且通常是处理时间。这对于那些在近似值上提供可证明的误差界限的算法非常重要。 如果这些错误界限是基于数据按序到达的，那么当为算法提供具有可变事件时间偏差的无序数据时，就基本上没有任何意义。 窗口窗口是从有界或无界数据源获取数据，沿时间边界将其分割成有限大小的块并进行处理的概念。 下图展示了三种不同模式的窗口。 滚动窗口 滚动窗口将时间划分为固定长度的片段，如下图，窗口在整个数据集上均匀分布，并且是对齐的窗口，在某些情况下可能希望对数据的不同子集（如不同 key）上的窗口做一些偏移处理，以使得窗口结束时的负载能够均匀地分布到不同时间上，这是非对齐窗口（在第六章会详细说明）的一个实例。 滑动窗口 滚动窗口的一般化形式，通过一个固定的总长度和固定的周期来定义。如果周期小于总长度，窗口会互相重叠，周期与总长度相等便是滚动窗口，如果周期大于总长度，便得到只处理部分子集数据的抽样窗口。滑动窗口通常是对齐的，但在一些特定案例中为了提升性能也可以是非对齐的。 会话窗口 会话窗口是动态窗口的一个实例，会话由一系列事件组成，当不活动时间超出设定的超时时间后会话结束。会话将时间上相关的一系列行为聚集到一起，通常被用来分析用户行为。会话窗口有趣的地方在于它们的长度取决于相关的真实数据，它们也是经典的非对齐窗口。 处理时间窗口 处理时间窗口有一些很好的性质： 简单性 判断窗口完整性的方法非常直接 如果你希望根据数据在数据源中被观察到的时间来处理信息，处理时间窗口正是你所需要的。许多监控的场景正好属于此类。 处理时间窗口的一大缺陷也很明显：如果问题中的数据有与其相关的事件时间，那么这些数据必须以事件时间的顺序到达，处理时间窗口才能反映出它们真实发生的时间。但不幸的是，顺序的事件时间数据在大多数真实世界的分布式输入源中并不常见。 一个简单的例子，手机 app 收集用户数据并用于后续处理，如果手机设备在某段时间离线，在这段时间内收集的数据需要在恢复在线后才会上传，这意味着数据在事件时间上可能误差若干分钟，小时，天甚至周。使用处理时间窗口在这样的数据集上不可能得到任何有用的结论。 另一个例子，考虑一个从各大洲收集数据的全球性服务，如果在带宽受限的跨大陆线路上出现的网络问题减小了带宽/增大了延迟，部分数据到达时间就会出现明显延迟。这时处理时间窗口不再能代表事件真实发生的时间，只能代表事件到达处理管道的时间，可能包含了旧数据和新数据的任意组合。 事件时间窗口 事件时间窗口是窗口的黄金标准。在2016年之前，大多数数据处理系统缺少对事件时间窗口的原生支持。而在今天，多数系统都能够在一定程度上提供原生对事件时间窗口的支持。 下图是对无界数据源进行一个小时滚动窗口划分的样例，数据会根据事件时间划分到对应窗口。 事件时间窗口可以是动态大小的，下图是对无界数据源进行会话窗口划分的样例。与批处理中从固定大小窗口中生成会话相比，这里不会再出现会话被分割的现象。 由于事件时间窗口在处理时间中总是会比窗口的实际时长存在更长时间，因此事件时间窗口有两个显著的缺陷： 缓存 由于更长的窗口存在时间，更多的数据需要被缓存。这并不是一个很严重的问题，因为在数据处理系统依赖的资源中，持久化存储的成本通常是最低的。并且很多聚合操作比如求和求平均数并不需要缓存完整的输入数据集合，只需要进行增量计算，这只需要很小的中间状态。 完整性 考虑到我们并没有一个好办法来得知我们是否已经得到了一个窗口中的全部数据，因此我们也不知道应该在何时发出窗口数据的处理结果。对很多不同类型的输入，一些系统可以通过水位线给出一个合理的窗口完成时间的启发式预测结果。但对于正确性要求极高的场景，唯一可靠的方法是让用户决定他们希望何时发出窗口的处理结果以及如何在后续修正这些结果。","link":"/2021/12/07/streaming-systems-chapter1/"},{"title":"《Streaming Systems》第三章 水位线","text":"到目前为止，我们是从用户或数据科学家的角度来看待流式系统的。在这一章，我们会从流式系统底层实现的角度来看待同样的问题。我们会讨论水位线如何在数据到达时创建、怎样在数据处理的 pipeline 中传播，以及怎样影响着输出的时间戳。 定义考虑任意一个持续获取数据并产生输出的 pipeline，我们希望解决的问题是：何时可以认为关闭一个事件时间窗口是安全的？ 一个很自然的想法是简单地根据当前的处理时间。但第一章中已经提到，数据处理和传输并不是瞬间完成的，处理时间和事件时间之间存在偏差，任何 pipeline 中出现的一些细微影响都可能导致数据被分配到错误的窗口中。我们无法对窗口做出任何保证。 另一个直观但并不正确的方法是考虑 pipeline 处理数据的速率。速率会随着输入、可用资源等属性的变化而变化，并且也并不能回答关于完整性的问题。速率指标可能可以用于检测处理过程中出现的一系列暂时性的问题（宕机、网络错误等）或持久性的问题（需要修改逻辑的应用层错误以及人为干预等），但它并不能告诉我们哪怕是任意一条数据是否已经被 pipeline 所处理，这显然不能保证输出的正确性。 为了得到一个更为可靠的度量过程的方法，我们对流式数据做出如下基本假设：所有数据都有一个与之关联的逻辑上的事件时间戳。在某些情况下，我们可以将事件最初发生时的时间作为逻辑上的事件时间戳。接下来我们就可以考虑这样的时间戳在 pipeline 中的分布。在 pipeline 中，正在被处理的数据时间戳会形成一个如下图所示的分布： 数据会被输入到 pipeline 中，经过处理，最终被标记为已完成。任何一条数据，要么是 ”in-flight“ 状态，即被接收到但尚未处理，要么是 ”completed“ 状态，即这条数据不再需要任何处理操作。参考该图，如果从事件时间的角度考虑数据的分布，随着时间推移，新的数据会从右侧加入到 ”in-flight“ 部分，越来越多的数据会被从 ”in-flight“ 部分移动到 ”completed“ 部分。 在这个分布中关键的一点在于，”in-flight“ 部分最左侧，表示着 pipleline 中尚未被处理的最早的事件时间戳。我们用这个值来定义水位线： 水位线是单调递增的尚未完成工作的最早时间戳。 注意这里提到了单调性，目前的讨论还没有涉及到这一点。如果我们只考虑最早的未完成事件时间，那么水位线并不总是单调的，因为我们没有对输入数据做出任何假设。我们会在之后讨论这一问题。 这个定义提供了两个有用的基本属性： 完整性 如果水位线超过了时间戳 $T$，根据单调性，可以保证不需要为在 $T$ 或之前及时到达的数据（非迟到数据）做出任何额外处理。因此，我们可以正确地发出 $T$ 之前的聚合计算结果。 可见性 如果有数据在 pipeline 中被卡住了，水位线就不会前进。更进一步，我们可以通过检查阻止水位线前进的数据来找到问题原因。 在数据源创建水位线第二章中提到，所有水位线都可以被分为两大类：完美水位线 和 启发式水位线，回顾第二章中这两种水位线的对比： 不管是完美的还是启发式的，水位线创建后其类型便不再变化。至于应该创建完美的还是启发式的水位线，这很大程度上取决于消费的数据源的性质。 完美水位线的创建完美水位线提供了严格保证：事件时间在水位线之前的数据不可能再出现。使用完美水位线的 pipeline 不需要处理迟到数据。对于现实世界中大多分布式数据源，实现完美水位线并不现实。以下是几个可以创建完美水位线的例子： 进入时间戳 一个将数据进入系统的时间戳记为事件时间的数据源可以创建完美水位线，数据源只是简单地跟踪系统发现数据时的当前处理时间。这也是2016年之前几乎所有支持窗口的流式系统所使用的方法。 因为事件时间（实际上是处理时间）在单一数据源上是单调递增的，所以系统对后续的输入数据有着完备的认识。因此，事件时间的过程和窗口语义很容易推理和实现。但其缺点在于，水位线和数据自身的事件时间并无关联。 时序日志的静态集合 一个规模不变且按时序排序的日志数据源（比如 Apache Kafka 中有着静态分区的 topic，每个分区中的事件时间是单调递增的）可以在其上创建完美水位线。数据源只需要跟踪所有静态分区集合中未处理数据的最小事件时间即可，也就是每个分区中最近一条读到的记录中的最小事件时间。 准确地说，与其说日志数量需要是静态的，不如说是系统事先知道任何给定时刻的日志数量。一个更为复杂的数据源可能由动态选择的输入日志组成，比如 Pravega，但这也可以构造出完美水位线。只有当任意给定时刻动态集合中的日志数量不确定时（下一节中的例子），才需要退而求其次使用启发式水位线。 与进入时间戳类似，由于静态分区集合中的事件时间是单调递增的，所以系统对即将到来的时间戳有着完美的认知。这实际上是有界无序数据处理的一种形式，集合中跨已知分区所带来的无序性会被所有分区中已观察到的最小事件时间所限制。 通常来说，能够保证分区中的时间戳单调递增的唯一方法是当数据写入到分区时分配时间戳。比如 web 前端将日志事件直接写入 Kafka。尽管这样的场景也是有一定限制的，但这显然比用进入数据处理系统的时间戳作为事件时间有用很多，因为水位线此时能够跟踪数据中有意义的真实事件时间。 启发式水位线的创建启发式水位线仅仅提供这样一种 预测：事件时间小于水位线的数据不会再出现。使用启发式水位线的 pipeline 可能需要想办法处理 迟到数据。如果启发式水位线构造合理，迟到数据会非常少，但如果系统希望支持需要正确性的用户场景，它需要为用户提供处理迟到数据的方法。 对现实世界中大多数分布式输入数据源，构造完美水位线从计算或操作上来说是不现实的，但我们可以利用输入源的特征构建一个具有高准确度的启发式水位线。以下是两个启发式水位线的例子： 时序日志的动态集合 考虑一个由结构化日志文件组成的动态集合（每个单独的文件中包含事件时间单调递增的日志记录但不同文件之间的事件时间没有关联），完整的日志文件（即 Kafka 中的分区）集合在运行时不可知。这样的输入在由多个独立团队构建且管理的全局服务中很常见。这种情况下很难创建完美水位线。 即便在不知道输入的全部信息的情况下，通过跟踪集合中未处理数据的最小事件时间、管理增长率以及利用诸如网络拓扑和带宽等外部信息，依然可以创建一个非常精确的水位线。 Google Cloud Pub/Sub Pub/Sub目前不保证有序交付，即便一个单独的publisher按序发布两条信息，仍然有很小的概率在交付时出现乱序（这是由底层架构的动态本质决定的，该架构可以在没有用户干预的情况下面对高吞吐量时进行扩容），因此，无法对Cloud Pub/Sub创建完美水位线。但Cloud Dataflow团队依然利用Cloub Pub/Sub中的可用信息构建了合理且精确的启发式水位线。 考虑用户玩手机游戏的场景，他们的得分会发送到pipeline进行处理，大致可以认为，对任意作为输入的手机设备，提供完美水位线是不可能的。因为设备可能在一段时间内离线，因此无法提供任何对输入完整性的评估。但是可以为在线设备的输入完整性构造水位线，从提供低延迟结果的角度看，在线用户是最为重要的，因此这样做并不是一个很大的缺点。 对启发式水位线，一般来说，对数据源信息了解越多，启发式方法就可以越好，迟到数据也会越少。考虑到数据源类型、事件分布、用例都会有很大不同，因此没有一种能够适用于所有情况的解决方法。但无论是完美水位线还是启发式水位线，在数据源创建水位线后，系统可以在 pipeline 中传播水位线，完美水位线在下游仍然是完美的，启发式水位线也依然是启发式的。水位线的好处在于：可以将在 pipeline 中追踪完整性的复杂问题缩小到在数据源创建水位线的问题。 水位线传播理解水位线传播水位线传播和输出时间戳窗口重叠的情形百分位水位线处理时间水位线","link":"/2021/12/11/streaming-systems-chapter3/"},{"title":"搬瓦工 VPS 的 Network abuse Mass Mailing 问题","text":"今天凌晨收到搬瓦工发送的邮件，提示 VPS 服务被停止，控制台显示停止原因为 Network abuse: Mass Mailing ，细节信息如下： We have detected a large number of outgoing SMTP connections originating from this server. This usually means that the server is sending out spam. 问题分析可以看出，因为服务器与外界建立了过多SMTP连接，从而搬瓦工认为服务器正在发送大量的垃圾邮件，因此暂停了服务。 下图是搬瓦工在控制台给出的部分信息： 对于我目前购买的服务，每次出现滥用网络资源的问题会扣除100分，总分是1000分，如果在一年内扣分达到1000分，vps 服务会一直暂停到该年年底。搬瓦工给出的解决方法是在服务恢复后重新安装操作系统。 在问题出现时，我的 VPS 上部署了两个服务，一个是 Shadowsocks（Python实现），另一个是 V2Ray，都用于科学上网，V2Ray为主，Shadowsocks为辅。V2Ray 使用的协议是 WebSocket + TLS，并通过 Cloudflare 中转流量，具体细节可以参考这篇博客。 在此之前，我的 VPS 已经平稳运行了接近3年，参考了一些网上的分析，该问题应该不是因为 VPS 被人恶意访问导致的，而大概率是使用科学上网服务的客户端电脑上有恶意软件大量发送邮件，而这些请求经过了 VPS 中转，从而导致 VPS 建立了大量 SMTP 连接。 由于担心直接在原操作系统上重启后再次发生同样的问题，我直接重新安装了操作系统，因此无法通过日志定位这些邮件是经过 Shadowsocks 还是 V2Ray 发出。但我平时几乎不使用Shadowsocks，而且 V2Ray 目前有多人共享，因此大概率是经过 V2Ray 发出的。 问题预防为了防止再次出现此问题，一种可能的方法是让 VPS 禁止 SMTP 的出流量。这可以通过 Linux 中的 iptables 工具实现。关于 iptables 相关介绍和使用方法可以参考 Arch wiki 和 CentOS wiki。以下的介绍和命令均基于 CentOS 7.9 发行版。 iptables 使用iptables 中的 filter table 默认包含了三种规则链： INPUT 所有以主机为目的地的数据包 OUTPUT 所有源自主机的数据包 FORWARD 数据包的源和目的地都不是主机，但会经过主机路由 为了禁止 SMTP 的出流量，可以在 OUTPUT 和 FORWARD 中添加相应的规则（经测试发现目前 FORWARD 链中没有数据包经过，但保险起见也同样添加此规则）。 首先查看添加规则前的 iptables 信息： 123456789[root@vps-host ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationChain FORWARD (policy ACCEPT)target prot opt source destinationChain OUTPUT (policy ACCEPT)target prot opt source destination 初始的 iptables 中不包含任何规则，所有数据包均同意接收或发送，使用以下命令通过过滤25端口TCP报文的方式禁止 STMP 出站： 12[root@vps-host ~]# iptables -A FORWARD -p tcp --dport 25 -j DROP[root@vps-host ~]# iptables -A OUTPUT -p tcp --dport 25 -j DROP 重新查看添加规则后的 iptables： 1234567891011[root@vps-host ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationChain FORWARD (policy ACCEPT)target prot opt source destinationDROP tcp -- anywhere anywhere tcp dpt:smtpChain OUTPUT (policy ACCEPT)target prot opt source destinationDROP tcp -- anywhere anywhere tcp dpt:smtp 可以看出在 FORWARD 和 OUTPUT 中均已有相应规则。在 VPS 上通过 wget 命令测试连接任意 IP 的 25 端口，然后查看 iptables 的数据统计情况： 123456789101112131415[root@vps-host ~]# wget 1.1.1.1:25--2022-03-24 21:25:10-- http://1.1.1.1:25/正在连接 1.1.1.1:25... ^C[root@vps-host ~]# iptables -L -vChain INPUT (policy ACCEPT 2384 packets, 443K bytes) pkts bytes target prot opt in out source destinationChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 DROP tcp -- any any anywhere anywhere tcp dpt:smtpChain OUTPUT (policy ACCEPT 2311 packets, 413K bytes) pkts bytes target prot opt in out source destination 2 120 DROP tcp -- any any anywhere anywhere tcp dpt:smtp[root@vps-host ~]# 可以看出在 OUTPUT 中，记录了有 2 个数据包被丢弃，说明规则应用正确。 规则持久化以上命令中定义的规则在重启机器后会失效，为了能够将规则持久化，可以使用 iptables-save 和 iptables-restore 命令。 iptables-save 命令会将 iptables 中的规则打印到标准输出，为了持久化，可以将输入重定向到文件中： 1[root@vps-host ~]# iptables-save &gt; iptables-disable-stmp 这里的文件名可以任取。iptables-restore 命令默认会从标准输入恢复规则，后续可以使用输入重定向将该文件的规则恢复： 1[root@vps-host ~]# iptables-restore &lt; iptables-disable-stmp 为了可以实现开机自行加载规则，一个简单的方法是在 root 用户目录下的 .bashrc 文件中添加该恢复命令： /root/.bashrc12# iptables disable SMTPiptables-restore &lt; /root/iptables-disable-smtp 总结VPS 的安全是一个不可忽视的问题，特别是用于科学上网的 VPS，因为一旦出现后不仅没法通过 Google 搜索资料，而且 Github 的访问也会出现问题，如果 IP 被封还无法使用 ssh 连接。平时使用代理时尽量不要使用全局代理，同时分享给多人使用也会提升出问题的风险。 iptables 提供了极其强大的防火墙功能，本文中介绍的内容只是针对该具体问题的解决方法，后续可以考虑添加 INPUT 规则，仅接收符合规则要求的数据包，从而进一步提升安全性。 参考资料[1] https://zhuanlan.zhihu.com/p/26282070[2] https://glglife.com/index.php/2021/09/25/ban-wa-gong-massmailing-wen-ti-jie-jue/[3] https://www.cyberciti.biz/faq/how-to-save-iptables-firewall-rules-permanently-on-linux/","link":"/2022/03/24/vps-mass-mailing/"},{"title":"虚拟机类加载机制","text":"“代码编译的结果从本地机器码转变为字节码，是存储格式发展的一小步，却是编程语言发展的一大步。” —— 周志明 《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 以下内容整理自周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 类加载机制：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换、解析和初始化，最终形成可以被虚拟机直接使用的Java类型。 类加载时机类的生命周期 加载 Loading 连接 Linking 验证 Verification 准备 Preparation 解析 Resolution 初始化 Initialization 卸载 Unloading 其中，加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序开始（并非进行 或 完成）。解析阶段在某些情况下可以在初始化阶段之后再开始，为了支持Java语言的运行时绑定。 必须对类进行初始化的情况虚拟机严格规定有且只有以下5种情况必须立即对类进行[初始化](#初始化)（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令，如果类没有进行过初始化，则需要先触发其初始化。典型场景： 使用new关键字实例化对象时 读取或设置一个类的静态字段时（被final修饰的静态字段除外） 调用一个类的静态方法时 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 初始化一个类时，如果其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个主类。 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 主动引用和被动引用 主动引用：以上五种场景中的行为称之为对一个类进行主动引用 被动引用：除主动引用外，所有引用类的方式称为被动引用，不会触发类初始化，常见例子： 通过子类引用父类的静态字段，不会导致字类初始化 通过数组定义来引用类，不会触发此类初始化 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，不会触发定义常量的类的初始化 接口与类加载过程的区别 接口也有初始化过程 在第3种类需要开始初始化的场景中，接口在初始化时，并不要求其父接口全部都完成了初始化，只有在用到父接口的时候才会初始化。 类加载过程加载在加载阶段，虚拟机需要完成以下3件事情： 通过一个类的全限定名获取定义此类的二进制字节流 未指明从何处、怎样获取。应用实例： 从ZIP包中读取：JAR、EAR、WAR 从网络中获取：Applet Proxy，代理类的二进制字节流 由其它文件生成：JSP 从数据库中读取 对于非数组类，开发人员可以通过自定义的类加载器控制字节流的获取方式。 对于数组类，由Java虚拟机直接创建。遵循以下规则： 数组组件类型是引用类型，递归采用加载过程加载组件类型，数组C将在加载该组件类型的类加载器的类名称空间上被标识 数组组件类型不是引用类型，Java虚拟机会把数组C标记为与引导类加载器关联 数组类的可见性与它的组件类型的可见性一致，如果组件类型不是引用类型，数组类的可见性默认为public 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 二进制字节流按照虚拟机所需格式存储在方法区中 方法区中的数据存储格式由虚拟机实现自行定义 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 并未明确规定存储在Java堆中 对于HotSpot虚拟机，Class对象存放在方法区中 注：加载阶段与连接阶段的部分内容是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这两个阶段的开始时间仍然保持着固定的先后顺序。 验证验证阶段的目的：确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 Java语言本身是相对安全的语言（相对于C/C++），但Class文件不一定由Java源码编译而来，在字节码语言层面上，可能会因为载入有害字节流导致系统崩溃，所以验证是虚拟机对自身保护的一项重要工作。 验证阶段大致会完成4个阶段的检验动作 文件格式验证 验证字节流是否符合Class文件格式的规范，并且能被当前版本虚拟机处理 可能包括的验证点： 是否以魔数 0xCAFEBABE 开头 主、次版本号是否在当前虚拟机处理范围之内 常量池中是否有不被支持的常量类型 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量 … 通过这个阶段验证后，字节流进入内存方法区中进行存储，后面3个验证阶段全部是基于方法区的存储结构进行的 元数据验证 对字节码描述的信息进行语义分析，保证其描述的信息符合Java语言规范的要求 可能包括的验证点： 这个类是否有父类（除了java.lang.Object之外） 这个类的父类是否继承了不允许被继承的类（被final修饰的类） 如果这个类不是抽象类，是否实现了其父类或接口中要求实现的所有方法 类中的字段、方法是否与父类产生矛盾 … 字节码验证 通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的 对类的方法体进行的校验分析，例如： 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的 … 符号引用验证 发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在[解析](#解析)阶段中发生 目的是确保解析动作能正常执行 对类自身之外（常量池中的各种符号引用）的信息进行匹配性校验 通常需要检验的内容： 符号引用中通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段 符号引用中的类、字段、方法的访问性是否可被当前类访问 … 如果无法通过验证，将会抛出一个java.lang.IncompatibleClassChangeError异常的子类，如： java.lang.IllegalAccessError java.lang.NoSuchFieldError java.lang.NoSuchMethodError … 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段。 进行内存分配的仅包括类变量（被static修饰的变量） 关于初始值 通常情况下是数据类型的零值 特殊情况：类字段的字段属性表中存在ConstantValue属性，变量会被初始化为ConstantValue属性所指定的值 解析解析阶段是虚拟机将常量池内的符号引号替换为直接引用的过程。 直接引用与符号引用 符号引用（Symbolic References） 以一组符号描述所引用的目标 符号可以是任意形式的字面量 满足使用时能无歧义地定位到目标即可 与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中 直接引用（Direct References） 直接引用可以是： 直接指向目标的指针、相对偏移量 能间接定位到目标的句柄 与虚拟机实现的内存布局相关，引用的目标必定已经在内存中存在 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。后面3种与JDK 1.7新增的动态语言相关。 前4种引用的解析过程 类或接口的解析 假设当前代码所处类为D，要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用，虚拟机完成解析需要以下三个步骤： 如果C不是一个数组类型，虚拟机会把代表N的全限定名传递给D的类加载器去加载类C 如果C是一个数组类型，并且数组的元素类型为对象，会按照第1点的规则加载数组元素类型，接着由虚拟机生成一个代表此数组维度和元素的数组对象 如果上面步骤没有出现任何异常，C在虚拟机中实际上已经成为一个有效的类或接口，但在解析完成之前还要进行符号引用验证，确认D是否具备对C的访问权限。如果发现不具备访问权限，将抛出java.lang.IllegalAccessError异常 字段解析 要解析一个未被解析过的字段符号引用，首先将会对字段表内class_index项中索引的CONSTANT_Class_info符号引用，也就是字段所属的类或接口的符号引用。如果解析成功，将这个字段所属的类或接口用C表示，虚拟机规范要求按照如下步骤对C进行后续字段搜索： 如果C本身包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束 否则，如果在C中实现了接口，将会按照继承关系从下往上递归搜索各个接口和它的父接口，如果接口中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束 否则，如果C不是java.lang.Object的话，将会按照继承关系从下往上递归搜索其父类，如果在父类中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束 否则，查找失败，抛出java.lang.NoSuchFieldError异常 如果查找过程中成功返回了引用，将会对这个字段进行权限验证，如果不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常。 在实际应用中，虚拟机的编译器实现可能会比上述规范要求更加严格。如果有一个同名字段同时出现在C的接口和父类中，或者同时在自己或父类的多个接口中出现，编译器将可能拒绝编译。 类方法解析 类方法解析的第一个步骤与字段解析相同。如果解析成功，将这个方法所属的类用C表示，接下来虚拟机会按照如下步骤进行后续类方法搜索： 类方法和接口方法符号引用的常量定义是分开的，如果在类方法表中发现class_index中索引的C是个接口，直接抛出java.lang.IncompatibleClassChangeError异常 如果通过了第1步，在类C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束 否则，在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束 否则，在类C实现的接口列表及它们的父接口中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果存在匹配的方法，说明类C是一个抽象类，查找结束，抛出java.lang.AbstractMethodError异常 否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError 如果查找过程成功返回了直接引用，将会对这个进行权限验证，如果不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常。 接口方法解析 接口方法也需要解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用。如果解析成功，用C表示这个接口，接下来虚拟机会按照如下步骤进行后续接口方法搜索： 与类方法解析不同，如果在接口方法表中发现class_index中的索引C是类而不是接口，直接抛出java.lang.IncompatibleClassChangeError异常 否则，在接口C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束 否则，在接口C的父接口中递归查找，直到java.lang.Object类（包括Object类）为止，如果有简单名称和描述符都与目标相匹配的方法，则返回这个方法的直接引用，查找结束 否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError异常 由于接口中的所有方法默认都是public的，所以不存在访问权限的问题，因此接口方法的符号引用解析应当不会抛出java.lang.IllegalAccessError异常 初始化在前面的类加载过程中，除了在[加载](#加载)阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中的字节码。 在准备阶段，变量已经赋过一次初始值，在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源。（执行类构造器&lt;clinit&gt;()方法的过程）。 关于&lt;clinit&gt;()方法 &lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并生成的 收集顺序是由语句在源文件中出现的顺序决定的 静态语句块只能访问到定义在静态语句块之前的变量 静态语句块对定义在它之后的变量可以赋值，但不能访问123456789public class Test { static { // 给变量赋值可以正常编译通过 i = 0; // 这句话编译器会提示&quot;非法向前引用&quot; System.out.print(i); } static int i = 1;} &lt;clinit&gt;()方法与实例构造器&lt;init&gt;()方法不同 不需要显式地调用父类构造器，虚拟机会保证父类的&lt;clinit&gt;()方法已经执行完毕 由于父类的&lt;clinit&gt;()方法先执行，父类中定义的静态语句块要优先于子类的变量赋值操作 下例中，字段B的值是2123456789101112static class Parent { public static int A = 1; static { A = 2; }}static class Sub extends Parent { public static int B = A;}public static void main(String[] args) { System.out.println(Sub.B);} &lt;clinit&gt;()方法对于类或者接口来说并不是必须的 如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成此方法 接口与类的&lt;clinit&gt;()方法的异同 接口中不能使用静态语句块，但有变量初始化的赋值操作，因此接口与类一样都会生成&lt;clinit&gt;()方法 接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法，只有当父接口中定义的变量使用时，父接口才会初始化 接口的实现类在初始化时一样不会执行父接口的&lt;clinit&gt;()方法 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁、同步 如果多个线程同时去初始化一个类，只会有一个线程去执行这个类的&lt;clinit&gt;()方法，其他线程需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕 如果一个类的&lt;clinit&gt;()方法中有耗时很长操作，可能造成多个线程阻塞 类加载器虚拟机设计团队把类加载阶段中“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到虚拟机外部去实现，以便让应用程序自己决定去获取所需要的类。实现这个动作的代码模块被称为“类加载器”。 类与类加载器类加载器虽只用于实现类的加载动作，但它在Java程序中起到的作用远远不限于类加载阶段。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性。每个类加载器，都拥有一个独立的类名称空间。 这也就是说，比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义。这里说的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判断等情况。 类加载器的种类从Java虚拟机的角度来讲，只存在两种类加载器： 启动类加载器（Bootstrap ClassLoader） 使用C++实现（仅限于HotSpot） 虚拟机自身的一部分 所有其他的类加载器 虚拟机外部 继承自抽象类java.lang.ClassLoader 从Java开发人员角度来看，类加载器可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器： 启动类加载器（Bootstrap ClassLoader） 将&lt;JAVA_HOME&gt;/lib目录中的，或者被-Xbootclasspath参数指定的路径中的虚拟机识别的类库加载到虚拟机内存中， 无法被Java程序直接引用 如果需要把加载请求委派给引导类加载器，直接使用null即可 扩展类加载器（Extension ClassLoader） 由sun.misc.Launcher $ExtClassLoader实现 负责加载&lt;JAVA_HOME&gt;/lib/ext目录中的，或被java.ext.dirs系统变量所指定的路径中的所有类库 开发者可以直接使用 应用程序类加载器（Application ClassLoader） 由sun.misc.Launcher $AppClassLoader实现 一般也称为系统类加载器 负责加载用户类路径（ClassPath）上所指定的类库 开发者可以直接使用 如果应用程序没有自定义过自己的类加载器，一般默认情况下使用此类加载器 双亲委派模型加载器之间的关系 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。类加载器之间的关系不会以继承关系来实现，而是都使用组合关系来复用父加载器的代码。 工作过程：如果一个类加载器收到了类加载的请求，他首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此。只有当父类加载器反馈自己无法完成这个加载请求时，自类加载器才会尝试自己去加载。 意义： Java类随着类加载器一起具备了带有优先级的层次关系 保证Java程序稳定运作 实现简单，实现双亲委派的代码集中在java.lang.ClassLoader的loadClass()方法之中 破坏双亲委派模型双亲委派模型并不是一个强制性的约束模型，而是Java设计者推荐给开发者的类加载器实现方式。 到目前为止，双亲委派模型出现出3次较大规模的被破坏的情况。 JDK 1.2发布之前 双亲委派模型在JDK 1.2之后才被引入，而类加载器在JDK 1.0已经存在，需要向前兼容 添加了新的protected方法findClass() 模型自身缺陷 基础类可能需要调用回用户代码（JNDI） 解决：线程上下文类加载器（Thread Context ClassLoader） 对程序动态性追求 动态性：代码热替换、模块热部署等","link":"/2018/05/11/class-loader/"},{"title":"Java 内存模型","text":"“并发处理的广泛应用是使得Amdahl定律代替摩尔定律成为计算机性能发展源动力的根本原因，也是人类“压榨”计算机运算能力的最有力武器。“ ——周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 以下内容整理自周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 内存模型在物理计算机中，为了解决缓存一致性问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI、MOSI、Synapse、Firefly、Dragon Protocol等。 内存模型可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。 Java内存模型Java内存模型（Java Memory Model，JMM）试图屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。 注：这里和以下所说的Java内存模型都特指在JDK1.2之后建立起来并在JDK1.5中完备过的内存模型。 主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 变量（Variables）：与Java编程中的变量有所区别，它包括实例字段、静态字段和构成数组对象的元素，不包括局部变量与方法参数，因为后者是线程私有的。 注：如果局部变量是一个reference类型，它引用的对象在Java堆中可被各个线程共享，但是reference本身在Java栈的局部变量表中，它是线程私有的。 主内存（Main Memory）：所有的变量都存储在主内存中，主内存与物理硬件的主内存可以互相类比，但此处只是虚拟机内存的一部分。 工作内存（Working Memory）：每条线程有自己的工作内存，工作内存可与处理器高速缓存类比，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 注：关于主内存副本拷贝，对象的引用、对象中某个在线程中访问到的字段是有可能存在拷贝的，但不会有虚拟机实现成把整个对象拷贝一次。 内存间交互操作关于主内存与工作内存之间具体的交互协议，Java内存模型定义了以下8中操作来完成： lock（锁定） 作用于主内存变量，把一个变量标识为一条线程独占的状态。 unlock（解锁） 作用于主内存变量，把一个处于锁定状态的变量释放，变量释放后才可以被其他线程锁定。 read（读取） 作用于主内存变量，把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入） 作用于工作内存变量，把read操作从主内存得到的变量值放入工作内存的变量副本中。 use（使用） 作用于工作内存变量，把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量值的字节码指令时将会执行这个操作。 assign（赋值） 作用于工作内存变量，把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储） 作用于工作内存变量，把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入） 作用于主内存变量，把store操作从工作内存中得到的变量值放入主内存的变量中。 把一个变量从主内存复制到工作内存，要顺序地执行read和load操作，把一个变量从工作内存同步回主内存，要顺序地执行store和write操作。Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。 Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则： 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存 不允许一个线程无原因地（没有发生过任何assign操作）把数据从其工作内存同步回主内存中 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中 这8种内存访问操作以及上述规则限定，再加上volatile的一些特殊规定，就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。 特殊规则——volatile变量关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制。Java内存模型对volatile专门定义了一些特殊的访问规则。 volatile 关键字的作用1. 保证变量对所有线程的可见性 可见性：当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的 volatile变量只能保证可见性，Java中的运算并非原子操作，会导致volatile变量的运算在并发下是不安全的 volatile变量的运算在并发下不安全的例子： 123456789101112131415161718192021222324252627282930public class VolatileTest { public static volatile int race = 0; public static void increase() { race++; } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for (int i = 0; i &lt; THREADS_COUNT; i++) { // JDK1.8后可用Lambda表达式 threads[i] = new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } // 如果使用IDEA，这里的1需要改为2，因为多了一个Monitor Ctrl-Break线程 while (Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} 在这段代码中发起了20个线程，每个线程对race变量进行10000次自增操作，但运行程序输出的结果都是一个小于200000的数字。由于自增运算race++在Class文件中由4条字节码指令构成，当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此时是正确的，但是执行iconst_1、iadd指令时，其他线程可能已经把race的值加大了，操作栈顶的值变成了过期的数据，所以putstatic指令执行后就会把较小的race值同步回主内存中。 2. 禁止指令重排序优化普通变量仅仅保证在该方法执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。 指令重排序干扰程序并发执行的例子： 123456789101112131415161718Map configOptions;char[] configText;volatile boolean initialized = false;// 假设以下代码在线程A中执行// 模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;// 假设以下代码在线程B中执行// 等待initialized，代表线程A已经把配置信息初始化完成while (!initialized) { sleep();}// 使用线程A中初始化好的配置信息doSomethingWithConfig(); 在上例中，如果定义initialized变量时没有使用**volatile**修饰，就可能会由于指令重排序的优化，导致位于线程A中最后一句的代码initialized = true被提前执行，这样在线程B中使用配置信息的代码就可能出现错误。 **volatile**关键字禁止指令重排序的例子： 12345678910111213141516public class Singleton { private volatile static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; }} 代码是一段标准的DCL单例代码，观察加入和未加入**volatile关键字所生成汇编代码的差别，关键变化在于有volatile修饰的变量赋值后多执行了一个lock addl $0x0, (%esp)操作，这个操作相当于一个内存屏障**（Memory Barrier，指重排序时不能把后面的指令重排序到内存屏障之前的位置），指令中把ESP寄存器的值加0是一个空操作，IA32手册规定lock前缀的作用是使得本CPU的Cache写入内存，该写入动作也会引起别的CPU或者别的内核无效化其Cache。通过这样一个操作，可以让volatile变量的修改对其他CPU立即可见。 **volatile**能禁止指令重排序是因为CPU在指令重排时需要能正确处理指令依赖情况以保障程序能得出正确的执行结果，而lock addl $0x0, (%esp)指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这样便形成了“指令重排序无法越过内存屏障”的效果。 volatile 变量的特殊规则假定T表示一个线程，V和W分别表示两个volatile类型变量，那么在进行read、load、use、assign、store和write操作时需要满足如下规则： 只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行load动作。 只有当线程T对变量V执行的前一个操作是assign的时候，线程T才能对变量V执行store操作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行assign动作。 假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load或store动作，假定动作P是和动作F相应的对变量V的read或write动作；类似地，假定动作B是线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假定动作Q是和动作G相应的对变量W的read和write操作，如果A先于B，那么P先于Q。 volatile 使用总结volatile**关键字的运用场景**： 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 使用例子： 1234567891011volatile boolean shutdownRequested;public void shutdown() { shutdownRequested = true;}public void doWork() { while (!shutdownRequested) { // do stuff }} 在某些情况下，**volatile的同步机制的性能确实要优于锁（使用synchronized关键字或java.util.concurrent包里面的锁），但是由于虚拟机对锁实行的许多消除和优化，使得我们很难量化地认为volatile就会比synchronized快多少。大多数场景下volatile的总开销要比锁低。我们在volatile与锁之中选择的唯一依据仅仅是volatile**的语义能否满足使用场景的需求。 特殊规则——long和double型变量long和double的非原子性协定（Nonatomic Treatment of double and long Variables） Java内存模型要求8个操作都具有原子性，但是对于64位的数据类型——long和double，在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即虚拟机实现可以选择不保证64位数据类型的load、store、read和write这4个操作的原子性。 Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但“强烈建议”虚拟机把这些操作实现为具有原子性的操作。 在实际开发中，各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，因此编写代码时一般不需要把用到的long和double变量专门声明为volatile。 Java内存模型特征Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的。 原子性 (Atomcity)由Java内存模型直接保证的原子性变量操作包括read、load、assign、use、store和write，可以大致认为基本数据类型的访问和读写是具备原子性的。 如果应用场景需要一个更大范围的原子性保证，Java内存模型还提供了lock和unlock操作来满足这种需求，虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块synchronized关键字，在synchronized块之间的操作也具备原子性。 可见性 (Visibility)可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 Java内存模型通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式实现可见性。普通变量和volatile变量都是如此，它们的区别是，volatile变量保证了多线程操作时变量的可见性，普通变量不能保证这一点。 除了volatile之外，synchronized和final关键字也能实现可见性。 volatile 实现可见性 规则：见 [volatile变量的特殊规则](#volatile-变量的特殊规则) synchronized 实现可见性 规则：对一个变量执行unlock操作之前，必须先把此对象同步回主内存中（执行store、write操作）。 final 实现可见性 被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”引用传递出去，那在其他线程就能看见final字段的值。 有序性 (Ordering)Java程序中天然的有序性：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。 Java语言提供了volatile和synchronized关键字保证线程间的有序性。 volatile 实现有序性 volatile本身包含了禁止指令重排序的语义 synchronized 实现有序性 规则：一个变量在同一时刻只允许一条线程对其进行lock操作，这决定了持有同一个锁的两个同步块只能串行地进入。 先行发生原则 Java语言中有一个“先行发生”（happens-before）的原则。这个原则是判断数据是否存在竞争、线程是否安全的主要依据。 先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于B，其实就是说在发生B操作之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 Java内存模型下有一些天然的先行发生关系，无需任何同步协助就已经存在。如果两个操作之间的关系不在此列，并且无法通过下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意进行重排序。 程序次序规则 (Program Order Rule) 在一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说应该是控制流顺序。 管程锁定规则 (Monitor Lock Rule) 一个unlock操作先行发生于后面对同一个锁的lock操作，“后面”是指时间上的先后顺序。 volatile变量规则 (Volatile Variable Rule) 对一个volatile变量的写操作先行发生于后面对这个变量的读操作，“后面”同样是指时间上的先后顺序。 线程启动规则 (Thread Start Rule) Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则 (Thread Termination Rule) 线程中的所有操作都先行发生于对此线程的终止检测，可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。 线程中断规则 (Thread Interruption Rule) 对线程interrupt()方法的调动先行发生于被中断线程的代码检测到终端事件的发生，可以通过Thread.interrupted()方法检测到是否有终端现象。 对象终结规则 (Finalizer Rule) 一个对象的初始化完成先行发生于它的finalize()方法的开始。 传递性 (Transitivity) 如果操作A先行发生于操作B，操作B先行发生于操作C，那么操作A先行发生于操作C。 事件先后顺序与先行发生原则之间基本没有太大的关系，在衡量并发安全问题时，不要受到事件顺序的干扰，一切必须以先行发生原则为准。","link":"/2018/05/24/java-memory-model/"},{"title":"《Streaming Systems》第二章 数据处理的 What，Where，When 和 How","text":"第二章中通过一些具体的例子更详细地介绍了第一章中提到的数据处理模式。这一章涉及了提供可靠的乱序数据处理所需要的核心原则和概念，也就是能够推断时间的一系列工具。 学习路线 本书第一部分（The Beam Model）的大部分以及本章全部内容的讨论会涉及到五个核心概念，其中前两个概念在第一章中已经有所涉及： 事件时间和处理时间 的区别 窗口（windowing） 窗口是用于处理无界数据源的常用方法。 触发器（Triggers） 触发器是用于声明何时发出窗口结果的机制。触发器也使得在不同时间多次产生窗口的输出结果成为可能，这可以让我们进一步调整之前的输出结果。 水位线（Watermark） 水位线是有关事件时间中输入完整性的概念，一个时间值为 X 的水位线意味着：所有事件时间在 X 之前的输入数据都已经被观察到了。水位线是用于跟踪无界数据源处理过程的一个度量值。 聚合（Accumulation） 聚合模式指定了同一窗口的多个输出结果之间的关系。这些结果可能是完全无关的，也可能是相互重叠的。不同的聚合模式有着不同的语义和开销。 为了更好地理解这些概念之间的关系，可以从回答以下四个问题的角度来加深对这些概念的理解： What：需要计算出什么样的结果？答案是通过 pipeline 中不同类型的数据转换。 Where：结果计算发生在事件时间中的何处？答案是在 pipeline 中所使用的事件时间窗口。 When：结果在处理时间的何时被发出？答案是所使用的触发器和水位线（可选）。 How：用于改进最终结果的不同结果之间是怎样关联的？答案是使用的不同的聚合类型：忽略（disgarding）、累积（accumulating）、累积并撤销（accumulating and retracting） 批处理基础：What 和 Where What：数据转换（Transformations） 本章节以及书中大部分地方都会用到一个简单的例子：在一个有9条数据的数据集上根据键值计算整数和。假设现在有一个基于团队的手机游戏，我们希望构造一个 pipeline 来计算每个团队的分数，团队分数即为团队中每个用户的手机上传的单个分数的总和。 这里假设这9条数据都来自同一个团队，需要关注的属性只有三个： 分数：单个事件中的用户得分 事件时间：该得分事件发生的时间 处理时间：pipeline 观察到该得分的时间 将这9条数据用一个x轴表示事件时间，y轴表示处理时间的静态图表示出来，如下图所示： 在之后的每个例子中，都会有一小段 Apache Beam Java SDK 的伪代码，用于定义具体的 pipeline。对于一个从 I/O 源读取数据，解析（团队，分数）对，并且计算每个团队总分数的简单 pipeline，样例如下： 1234PCollection&lt;String&gt; raw = IO.read(...);PCollection&lt;KV&lt;Team, Integer&gt;&gt; input = raw.apply(new ParseFn());PCollection&lt;KV&lt;Team, Integer&gt;&gt; totals = input.apply(Sum.integersPerKey()); 在描述 pipeline 的代码段之后，会有一张图来展示对于单个键值，pipeline 在指定简单数据集上的处理过程。 图中的x轴表示事件时间，y轴表示处理时间，因此，真实时间是沿y轴从下往上的，这里用一根黑色的水平粗线表示处理时间的递增过程。每个输入是一个圆圈，其中的数字表示得分。这些圆圈在一开始是亮灰色的，进入 pipeline 后颜色会变深。 当 pipeline 发现数据后，它会将这些值累加到中间状态中，最终的聚合状态会作为输出发送出去。状态和输出是用矩形表示的，灰色表示状态，蓝色表示输出。状态聚合结果会显示在矩形上方。 对于上述例子中的 pipeline，在一个经典的批处理引擎上的处理过程如下所图示： 由于这是一个批处理 pipeline，它会不断累加状态直到处理过所有数据（用最上方的绿色虚线表示），最后会输出唯一的结果 48。 Where：窗口 以两分钟的滚动窗口为例，在 Beam 中，只需要简单增加 Window.into 的操作： 123PCollections&lt;KV&lt;Team, Integer&gt;&gt; totals = input .apply(Window.into(FixedWindows.of(TWO_MINUTES))) .apply(Sum.integersPerKey()); Beam 提供了可以同时在批处理和流处理中工作的统一模型。在批处理引擎中运行该 pipeline，对应的结果如下： 与之前一样，输入被累加到状态中，直到所有输入都被处理完成后才会产生最终输出。有了窗口之后这里会得到4个结果，分别对应着4个两分钟的事件时间窗口。 流处理：When 和 How When：触发器 触发器声明了在处理时间中窗口的输出应该在何时触发（触发器可能根据其他基于不同类型时间域中的工具来做出该决策，比如基于事件时间的水位线）。 尽管存在着众多可能的触发器语义，但在概念上只有两种通用类型的触发器，实际应用几乎总能归结为使用了其中的一种或两种的组合： 重复更新式触发器 随着窗口中内容的变化，周期性地生成更新后的窗口输出结果。更新可能发生在每个新数据到达后，或者在一定处理时间延迟后；更新周期的选择需要在延迟和处理开销之间做出权衡。 完整性触发器 在一定程度上确认窗口已经包含完整输入后输出窗口计算结果。这与批处理情况很类似：只在输入完整后才输出结果，区别在于这里的完整性范围只是针对单个窗口而非整个数据集。 重复更新式的触发器在流式系统中更为常用，它实现起来更为简单，也更容易理解。 完整性触发器相对来说没有那么常见，但它为流式系统提供了非常接近于批处理系统的语义，并且也提供了处理丢失和迟到数据的工具。 简单起见，首先考察针对每个数据都进行更新的重复更新式触发器： 1234PCollection&lt;KV&lt;Team, Integer&gt;&gt; total = input .apply(Window.into(FixedWindows.of(TWO_MINUTES)) .triggering(Repeatedly(AfterCount(1)))) .apply(Sum.integersPerKey()); 在流处理引擎中运行的结果如图： 这类触发器在某些场景下工作得很好，比如输出数据流会写入某些经常被用于查询结果的表中，这样的话对于某个给定窗口，在任何时候表中的内容总是最新的，并且这些值会随着时间逐渐收敛为最终的正确值。 但一大缺点在于，针对每条记录的触发器太过于啰嗦。当处理大规模数据时，类似求和之类的聚合可以在不损失信息的情况下有效地降低数据规模，特别是在有大量键值的情况下。此时，你可能更希望在经过一定的处理时间延迟后更新结果，比如每秒或每分钟。使用处理时间延迟的一个好处在于，输出流的数据规模在大量键值之间或不同窗口之间会变得更加统一。 有两种处理时间延迟的触发器设置方法：对齐延迟 和 非对齐延迟。一个对齐延迟的样例如下： 1234PCollection&lt;KV&lt;Team, Integer&gt;&gt; total = input .apply(Window.into(FixedWindows.of(TWO_MINUTES)) .triggering(Repeatedly(AlignedDelay(TWO_MINUTES)))) .apply(Sum.integersPerKey()); 事实上，基于微批处理（microbatch）的系统所提供的便是对齐延迟的触发器，比如 Spark Streaming。它的优点在于可预测性：所有窗口结果都在相同时刻有规律地进行更新，缺点也同样在于此：发生在同一时刻的更新会使得系统负载陡增。对此的解决方法是使用非对齐延迟，样例如下： 1234PCollection&lt;KV&lt;Team, Integer&gt;&gt; total = input .apply(Window.into(FixedWindows.of(TWO_MINUTES)) .triggering(Repeatedly(UnalignedDelay(TWO_MINUTES)))) .apply(Sum.integersPerKey()); 可以看出，非对齐延迟使得负载在时间上的分布更为均匀。 在一些用户场景中，结果可以简单地进行周期性更新，并逐渐趋于正确值，并且我们并不在意何时能保证正确，此时使用重复更新式的触发器是非常合适的。但是在对输入完整性要求比较高的情况下，需要通过一些方法来推断完整性，也就是下一节中的水位线。 When：水位线 水位线是用来回答 When 这个问题答案的一部分。水位线是描述事件时间中输入完整性的时间概念，它是系统用来度量相对于事件流中正在处理的记录的事件时间进度和完整性的方法。 在概念上，可以认为水位线是一个函数，$F(P)\\rightarrow E$，输入是处理时间中的某一时刻，返回一个事件时间中的时刻。 更准确地说，函数的输入是在 $P$ 时刻 pipeline 中正在观察水位线的位置其上游的所有状态：输入源、缓存数据、正在处理的数据等等。 系统会认为所有事件时间小于 $E$ 的输入都已经被处理，即断言小于事件时间 $E$ 的数据不会再出现。水位线的类型有两种，对于完美水位线，这样的断言是严格保证的，而对于启发式水位线，这只是一个猜测值。 完美水位线 对于那些我们对所有输入都有完整了解的场景，可以构建出完美的水位线。在这样的场景下，所有数据都会按时到达，不会迟到。 启发式水位线 对于众多分布式输入数据源，我们无法知道输入的完整信息，这种情况下的方法是提供一个启发式水位线。启发式水位线使用任何可获得的信息作为输入，提供一个尽可能准确的猜测。虽然在很多场景下这样的猜测是非常准确的，但是它仍然可能会出现错误，也就是出现迟到数据。之后会提到如何处理迟到数据。 水位线是构成之前提到的完整性触发器的基础。水位线是一个有趣且复杂的话题，在第三章中会深入分析。以下是一个使用水位线构建的完整性触发器的例子： 1234PCollection&lt;KV&lt;Team, Integer&gt;&gt; totals = input .apply(Window.into(FixedWindows.of(TWO_MINUTES)) .triggering(AfterWaterMark())) .apply(Sum.integersPerKey()); 水位线有趣的地方在于它们是一系列函数，这意味着有多个不同的函数 $F(P)\\rightarrow E$ 满足水位线的属性要求。水位线的算法与 pipeline 本身是无关的，在这一章中不会讨论水位线的实现细节。为了对比不同的水位线函数，这里我们在相同的数据集上使用了两种不同的水位线实现，在下图中，左侧是完美水位线，右侧是启发式水位线。在这两个例子中，窗口都是在水位线超出窗口结束时间后产生窗口结果的。 水位线的缺点可能有以下两种： 过慢 当水位线由于一些已知的未被处理数据所推迟时，如果仅仅依赖水位线的推进来产生结果，那么输出结果也会推迟。正如上图左侧 [12:02, 12:04) 的窗口。 很重要的一点是：尽管水位线提供了非常有用的完整性概念，但从延迟的角度来看，基于完整性来产生输出通常是不理想的。 过快 当启发式水位线推进过快时，事件时间在水位线之前的数据可能会迟到，上图右侧即出现了这一情况，正确结果应该是14，但输出是5。当我们关注正确性时，仅仅依赖水位线来决定何时发出结果是不够的。 水位线的这两个缺点说明了，仅仅依赖完整性的概念是无法使系统同时满足低延迟和正确性的。但如果对这两者都有需求，考虑到重复更新式的触发器可以提供低延迟但不保证正确性的更新，而水位线提供了正确性但延迟可能很高，所以我们其实可以把它们两者的能力结合到一起。 When：Early/On-Time/Late 触发器 两种主要类型的触发器：重复更新式触发器和完整性/水位线触发器，将它们结合到一起可能提供更强大的能力。Beam 意识到了这一点，并提供了一个标准水位线触发器的扩展版，它同时可以支持在水位线前或水位线后重复更新式触发。这就是 Early/On-Time/Late 触发器。它将触发器生成的结果分为三类： 若干个（可能为0）提前发出的结果，即使用重复更新式触发器在水位线到达窗口结束时间前周期性地发出结果。这弥补了水位线有时 过慢 的缺点。 单个的准时发出的结果，即使用完整性触发器在水位线达到窗口结束时间时发出的结果 若干个（可能为0）迟到的结果，即使用另一种重复更新式触发器在水位线超出窗口结束时间且有迟到数据到达后的某一时间发出结果。在使用完美水位线时，这样的结果不会出现。这弥补了水位线有时 过快 的缺点。 在下面样例中，我们将 pipeline 做如下更新：使用1分钟对齐延迟的周期性触发器来产生提前发出的结果，和一个针对每个记录都产生输出的触发器来产生迟到结果。 123456PCollection&lt;KV&lt;Team, Integer&gt;&gt; totals = input .apply(Window.into(FixedWindows.of(TWO_MINUTES))) .triggering(AfterWatermark() .withEarlyFirings(AlignedDelay(ONE_MINUTE)) .withLateFirings(AfterCount(1))) .apply(Sum.integersPerKey()); 在 Figure 2-10 中，完美水位线与启发式水位线产生的输出看起来非常不同，但使用新的触发器后这两者的输出看起来已经非常相似了。这里的结果与仅仅使用重复触发式触发器看起来也很类似，但因为有了水位线触发器的支持，在这里我们可以推断输入的完整性，从而可以更好地处理关心迟到数据的场景，比如外连接，异常检测等等。 此时的完美水位线与启发式水位线的一大区别在于窗口的生命周期。在完美水位线版本中，我们可以在水位线超出结束时间后立即丢弃该窗口的状态；而在启发式水位线版本中，考虑到可能有迟到数据，我们仍然需要维护窗口状态。但到目前为止，系统并不知道应该将状态维持多久，这是下一节中讨论的内容。 When：允许迟到的限度（垃圾收集） 在 Figure 2-11 中启发式水位线例子里，每个窗口的状态一直持续到样例的整个生命周期，用于处理迟到数据。但在现实中处理无界数据源时，无限制地保留窗口状态是不现实的。系统需要能提供限制窗口生命周期的方法。一个简单的方法是定义一个系统内允许迟到的上界，也就是相对于水位线来说，任意一条记录可能晚到的上界，超出这个晚到限制的数据会被丢弃。当定义了单个数据的迟到上界后，就已经能够准确定义窗口的状态应该维持到什么时候了：即水位线在窗口结束后达到迟到上界的时刻。 在事件时间中指定迟到数据上界可能看上去有点奇怪，但这的确是最好的方法。另一个可选的方法是在处理时间中指定上界（比如在水位线经过窗口结束时间后，在处理时间中再保留十分钟）。但后者可能使 pipeline 中的垃圾收集策略出现问题，比如 worker 宕机导致 pipeline 中断了几分钟，这会导致窗口无法处理本应该能够处理的迟到数据。通过在事件时间中指定延迟上界，垃圾收集可以与 pipeline 真实的处理过程绑定，这样可以降低窗口无法正确处理迟到数据的可能性。另外，并不是所有的水位线都是一样的，本书中提到的水位线都是 低水位线，它会悲观地去跟踪系统中未被处理的事件时间最早的数据。用低水位线处理迟到数据的好处是可以适应不断变化的事件时间偏差，提供尽可能最好的正确性保证。作为对比，某些系统可能用“水位线”表示其他事物。比如 Spark Streaming 中的水位线是高水位线，它会乐观地获取系统中事件时间最新的数据。在处理迟到数据时，高水位线会与用户所指定的阈值计算出一个时间值，系统可回收任何早于该值的窗口。换句话说，系统允许你指定在你的 pipeline 中事件时间的偏差上界。这样做在偏差可以保持在某个固定常数的 pipeline 中可以工作地很好，但相比低水位线模式可能更容易错误地丢失数据。 以启发式水位线为例，在 Figure 2-11 的基础上增加1分钟的迟到上界： 1234567PCollection&lt;KV&lt;Team, Integer&gt;&gt; totals = input .apply(Window.into(FixedWindows.of(TWO_MINUTES))) .triggering(AfterWatermark() .withEarlyFirings(AlignedDelay(ONE_MINUTE)) .withLateFirings(AfterCount(1)) .withAllowedLateness(ONE_MINUTE)) .apply(Sum.integersPerKey()); 在上图中，为了体现允许迟到带来的影响，添加了如下一些特征： 表示当前处理时间位置的黑色粗线上为每个窗口添加了在事件时间中迟到上界的标注。 当水位线超出窗口迟到上界时，该窗口会被关闭，即窗口所有的状态会被丢弃。在图中使用了虚线的矩形来表示窗口被关闭时所囊括的时间，虚线矩形右侧的尾巴表示窗口的迟到上界。 在这张图中，为第一个窗口额外增加了一条数据6。6是迟到数据，但在迟到上界之内，因此可以被包含到更新后的结果11中。但9在迟到上界后达到，所以被丢弃了。 关于迟到上界的最后两条旁注： 对于可以实现完美水位线的情况，不需要处理迟到数据，因此可以将迟到上界设为0。 当计算全时间段上的全局聚合，且键值数量很有限时，活动中窗口的数量不会超过键值的数量，只要键值数量是可控的，就不需要通过允许延迟的方式来限制窗口的生命周期。（比如根据不同浏览器类型分组，计算从网站出现以来它们各自访问的总次数） How：聚合 当触发器会为某个窗口发出多个结果时，就会遇到 How 这个问题：多个结果之间的关系是怎么样的？关于结果的聚合有三种不同的模式： 丢弃（Discarding） 当输出结果被发出后，存储的状态被立即丢弃。这意味着后续的结果与之前的结果之间是独立的。丢弃的模式在下游消费者可以自行进行聚合的场景下是很有用的。 累积（Accumulating） 当输出结果被发出的，状态依然保持，未来的输入会聚合到当前状态中。累积模式对于后续结果可以简单地覆盖之前结果的场景是很有用的。 累积并撤销（Accumulating and retracting） 与累积模式很类似，但在产生一个新的结果时，同样会为之前的某个或多个结果产生一个撤销。这就像是在说：”我之前告诉你的结果 X 是不对的，丢弃掉 X 这个结果，把它改成 Y“。在下面两种场景下，撤销是非常有用的： 当下游消费者需要在不同的维度上对数据重新分组时，新的值可能导致数据被分到不同的组中。这时不能简单地覆盖旧的结果，而需要用撤销来移除旧的值 当使用动态窗口（如会话）时，因为会发生窗口合并，所以新值出现可能会替换掉多个旧的窗口。 下面的例子展示了丢弃模式： 1234567PCollection&lt;KV&lt;Team, Integer&gt;&gt; totals = input .apply(Window.into(FixedWindows.of(TWO_MINUTES))) .triggering(AfterWatermark() .withEarlyFirings(AlignedDelay(ONE_MINUTE)) .withLateFirings(AfterCount(1)) .discardingFiredPanes()) .apply(Sum.integersPerKey()); 与 Figure 2-11 中积累模式的整体形状类似，但在这里所有矩形区域是不相互重叠的。 撤销模式样例如下： 1234567PCollection&lt;KV&lt;Team, Integer&gt;&gt; totals = input .apply(Window.into(FixedWindows.of(TWO_MINUTES))) .triggering(AfterWatermark() .withEarlyFirings(AlignedDelay(ONE_MINUTE)) .withLateFirings(AfterCount(1)) .accumulatingAndRetractingFiredPanes()) .apply(Sum.integersPerKey()); 图中的撤销使用红色矩形，由于与蓝色的矩阵重叠，因此看起来有点像紫色。矩形中两个输出值之间用逗号隔开以便区分。 最后是三种模式的最后一帧对比图： 关于存储和计算的成本开销，图中的三种模式从左到右是依次递增的。聚合模式的选择提供了在正确性、延迟和开销之间权衡的另一个维度。","link":"/2021/12/08/streaming-systems-chapter2/"}],"tags":[{"name":"Original","slug":"Original","link":"/tags/Original/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Interview","slug":"Interview","link":"/tags/Interview/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Arch","slug":"Arch","link":"/tags/Arch/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Streaming Systems","slug":"Streaming-Systems","link":"/tags/Streaming-Systems/"}],"categories":[{"name":"读书笔记","slug":"读书笔记","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"深入理解Java虚拟机","slug":"读书笔记/深入理解Java虚拟机","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"Streaming Systems","slug":"读书笔记/Streaming-Systems","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Streaming-Systems/"}]}
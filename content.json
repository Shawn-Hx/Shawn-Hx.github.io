{"pages":[{"title":"","text":"Basic 黄潇 （Shawn Huang） 1997.10.14 Education2015 - 2019 南京大学 软件学院 学士 2019 - now 清华大学 软件学院 工程硕士 Experience2018.7 - 2018.10 实习于 苏州微软工程院 Apache Flink Contributor 目前专注于流处理资源调度优化 Skills Language：Java, Python, C Framework：Flink, Spring Boot Database：MySQL, SQLite VCS：Git Tools：Vim, zsh, Docker OS：Arch Linux Hobbies 阅读 电影 魔方 Dota2 云玩家","link":"/about/index.html"}],"posts":[{"title":"Hello World","text":"关于博客很早就有了写博客的想法，但是耽搁到大三下才写下这第一篇博客，原因大概有这么几点。 最主要的原因是懒。我一直是个极其懒惰的人，微博只有转发，也从不发说说和朋友圈，更别说发布和更新博客了。 不仅如此，写博客还是一件极其麻烦的事情。如果要写博客，我是肯定不会在诸如CSDN这样的博客网站上写的，不仅界面丑陋而且充斥着各种抄袭、误导人的文章。既然如此那就得自己建站，买域名、买服务器，加上之后的部署和维护，极其麻烦，所以也一直没有动手。 当然还有很重要的一个问题是：博客应该写什么？ 看过阮一峰、廖雪峰、耗子哥、垠神等诸多dalao的博客，深感自己当前知识的匮乏、对技术理解之浅，对比之下觉得自己写出的技术博客必然会十分肤浅。而如果是记录一些踩过的坑，或是写课堂学习笔记又觉得没有太多的价值，也提不起写博客的兴趣，总之就这样一直搁置了下来。 直到前一阵子听说，GitHub Pages可以免费搭建个人博客，绑定域名，甚至能免费开启https，我这才又重新想起了写博客的事。几乎每天都在用的GitHub有这么方便的工具，我居然现在才知道，确实有点孤陋寡闻了。恰好最近在微信读书上看书，苦于看书时前面看后面忘，把博客作为读书总结归纳的地方再好不过。 创建仓库话不多说，我先改掉了GitHub的用户名（原来的用户名有点蠢），按username.github.io的命名要求新建了仓库。配置好了Jekyll，并学习了下基本的用法，用Jekyll创建了自己的博客并push到了我的仓库中。 JekyllJekyll是一个简单的Blog生成工具，只生成静态网页，但可以配合第三方服务。Jekyll可以免费部署在Github上。 Jekyll的安装很简单。首先需要在Mac上安装Xcode和Command-Line Tools。Xcode可以直接在App Store搜索下载，下载完成后在终端执行xcode-select --install后根据提示即可安装Command-Line Tools。 Mac OS X自带了Ruby，直接在终端下执行gem install jekyll即可完成安装。 如果系统自带的Ruby版本较低，安装时可能会提示出错，这时需要安装rvm，使用rvm安装和管理新版本Ruby。这个知乎提问的回答讲解比较具体。 接下来直接终端执行jekyll new myblog，jekyll会自动创建一个内容符合博客网站目录结构的myblog目录。在生成的myblog目录下，执行jekyll serve，即可在本地浏览器访问http://localhost:4000进行预览。 如果中途遇到缺少依赖的提示，使用gem install [package]安装即可。 最后将myblog目录下的内容push到之前创建的github仓库中，便可以访问到博客内容。 模版Jekyll有诸多主题模版，Github提供了一些可选的主题，可以在仓库设置中选择。除此之外，这里也提供了大量主题可供选用。 目前我使用的是默认的minima主题，也许以后有空的时候会摸索一下换个好看一点的。 域名GitHub Pages给博客提供的默认域名即为仓库名username.github.io。如果需要自定义域名，可以在项目根目录下创建CNAME文件，输入不带协议的自定义域名即可。 我是在GoDaddy购买的域名，原本在万网上发现.com .cn .net常用域名都已经被注册了（意料之中），后来发现.me域名不错，用在个人博客恰到好处，而万网并不提供.me域名的购买，于是最终在GoDaddy花了￥24购买了首年的huangxiao.me域名。 GitHub Pages从5月1日起可以为自定义域名支持HTTPS。新的IP地址不仅支持HTTPS，而且可以通过CDN加快访问速度，同时还能防范DDoS攻击。 如果自定义域名使用CNAME或ALIAS记录，那么仅需在仓库设置中勾选Enforce HTTPS选项即可。 如果自定义域名使用A记录，则需要设置A记录将自定义域名指向以下IP： 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 具体教程链接 Hello World于是便有了这一篇博客，以上记录的过程前前后后经过了几个星期的时间。因为太久不写文章，所以语言组织和表达能力还需要多加练习。 无论如何，总算是有了一个方便的写博客的地方，也有了第一篇博客文章。希望自己能够不断提高，写出和上面提到的dalao们一样高质量的博客文章。","link":"/2018/05/03/Hello-World/"},{"title":"Java 垃圾回收","text":"“Java 与 C++ 之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。” —— 周志明 《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 以下内容整理自周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 对象回收条件引用计数算法（Reference Counting）给对象添加一个引用计数器，每当有一个地方引用这个对象时，计数器的指加1；当引用失效时，计数器的指减1；任意时刻计数器为0的对象就是不可能再被使用的。 优点：实现简单，判定效率高 缺点：难以解决对象间循环引用问题 主流Java虚拟机均未选择引用计数算法来管理内存。 可达性分析算法（Reachability Analysis）通过一系列 GC Roots 对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连，则此对象不可用。 在Java中，可作为GC Roots的对象如下： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（一般说的Native方法）引用的对象 在主流的商用程序语言的主流实现中，都是通过可达性分析来判断对象是否存活的。 可达性分析算法对执行时间的敏感性 从GC Roots查找引用链 可作为GC Roots的节点主要在全局性的引用与执行上下文中 如果逐个检查这里面的引用会消耗很多时间 GC停顿 分析工作必须在一个能确保一致性的“快照”中进行 GC进行时必须停顿所有Java执行线程（Sun将其称之为“ Stop The World ”） 关于引用在JDK1.2前，Java中引用的定义为：如果reference类型的数据中存储的数值代表的是另一块内存的起始地址，就称这块内存代表着一个引用。 这样的定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用和没有被引用两种状态。无法描述一些“食之无味，弃之可惜”的对象。 在JDK1.2后，Java对引用的概念进行了扩充，将引用分为以下四种，这四种引用强度依次减弱。 强引用 Strong Reference 程序代码中普遍存在的引用 被引用的对象永远不会被垃圾收集器回收 软引用 Soft Reference 有用但非必需的对象 在系统将要发生内存溢出异常之前会把其关联对象列入回收范围之内进行第二次回收 弱引用 Weak Reference 被弱引用关联的对象只能生存到下一次垃圾收集发生之前 虚引用 Phantom Reference 不会对对象的生存时间构成影响 设置的唯一目的是能在对象被回收时收到系统通知 垃圾收集算法垃圾收集算法的实现涉及大量程序细节，且各个平台虚拟机操作内存的方法各不相同，因此以下整理的仅为几种算法的主要思想，并不关注其具体实现。 标记-清除算法（Mark-Sweep）标记－清除算法是最基础的收集算法，之所以说是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。该算法分为“标记”和“清除”两个阶段。 标记：标记出所有需要回收的对象 清除：在标记完成后统一回收所有被标记的对象 该算法的不足之处： 效率问题：标记和清除两个过程的效率都不高 空间问题：标记清除后会产生大量不连续的内存碎片 复制算法（Copying）复制算法的出现是为了解决效率问题。它的大体思路为：将可用内存按容量分为大小相等的两块，每次只使用其中一块。当一块的内存用完了，就将还存活着的对象复制到另一块上，然后把已使用过的内存空间一次清理掉。 优点：每次仅对半区进行回收，按顺序分配内存即可，实现简单，运行高效 缺点：将内存缩小为了原来的一半，代价巨大 现在的商业虚拟机都采用这种收集算法来回收新生代。 研究表明，新生代中的对象98%是“朝生夕死”的，所以不需要按照1:1的比例划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1。 在回收时，将Eden和Survivor中还存活着的对象一次性复制到另一块Survivor空间上，最后清理掉Eden和刚刚使用的Survivor空间。如果Survivor空间不够用，则需要依赖老年代内存进行分配担保（Handle Promotion）。 标记-整理算法（Mark-Compact）复制算法一般不能用于老年代，原因如下： 老年代对象存活率较高，需要进行较多复制操作，降低效率 为了不浪费50%的空间，需要额外空间进行分配担保，以应对对象100%存活的极端情况 “标记－整理”算法考虑到老年代的特点，其中标记过程与“标记－清除”算法相同，但后续步骤是让所有对象向一端移动，然后直接在清理掉端边界以外的内存。 分代收集算法（Generational Collection）当前商业虚拟机的垃圾收集都采用“分代收集”算法。 思想：把Java堆分为新生代和老年代，这样可以根据各个年代的特点采取适当的收集算法。 注：Minor GC 与 Full GC Minor GC 发生在新生代的垃圾收集动作 非常频繁，回收速度较快 Full GC / Major GC 发生在老年代的GC 经常会伴随至少一次的Minor GC 速度一般会比Minor GC慢10倍以上 垃圾收集器垃圾收集器是内存回收的具体实现。Java虚拟机规范中对垃圾收集器如何实现没有任何规定，因此不同厂商、版本的虚拟机提供的垃圾收集器区别很大。 以下收集器基于JDK1.7 Update 14后的HotSpot虚拟机。这个虚拟机包含的所有收集器如下图所示。 Serial 收集器 单线程收集器 简单高效 没有线程交互的开销，可以获得最高的单线程收集效率 最基本、发展历史最悠久 在JDK1.3.1之前是虚拟机新生代收集的唯一选择 目前为止依然是虚拟机运行在Client模式下的默认新生代收集器 ParNew 收集器ParNew收集器是Serial收集器的多线程版本。在实现上，这两者也共用了相当多的代码。 ParNew收集器是运行在Server模式下的虚拟机中首选的新生代收集器 ，一个与性能无关的重要原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 Parallel Scavenge 收集器Parallel Scavenge 收集器是使用复制算法、并行的多线程新生代收集器。 与ParNew收集器的不同之处： 关注点——吞吐量（Throughput） 吞吐量：CPU用于运行用户代码的时间与CPU总消耗时间的比值 吞吐量 ＝ 运行用户代码时间 / (运行用户代码时间＋垃圾收集时间) 高吞吐量意味着可以高效率地利用CPU时间，尽快完成运算任务 适合在后台运算不需要太多交互的任务 CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验 GC自适应调节策略（GC Ergonomics） 提供参数 -XX:+UseAdaptiveSizePolicy MaxGCPauseMillis参数更关注最大停顿时间 GCTimeRatio参数更关注吞吐量 参数打开后虚拟机会根据当前系统运行情况动态调整参数以提供最合适的停顿时间或最大吞吐量 Serial Old 收集器Serial Old 是 Serial 收集器的老年代版本。它是单线程收集器，使用“标记－整理”算法。主要意义是给Client模式下的虚拟机使用。 在Server模式下，它还有两大用途： 在JDK1.5及之前版本中与Parallel Scavenge收集器搭配使用 Parallel Scavenge 收集器架构中本身有PS MarkSweep收集器来进行老年代收集，并非直接使用Serial Old收集器，但是PS MarkSweep收集器与Serial Old的实现非常接近，所以在官方许多资料中都是都是直接以Serial Old代替PS 作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用 Parallel Old 收集器Parallel Old 自JDK1.6开始提供，是 Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。 在Parallel Old收集器出现前，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old (PS MarkSweep)收集器外别无选择。但老年代Serial Old收集器无法充分利用多CPU的处理能力，使用了Parallel Scavenge收集器未必能在整体应用上获得吞吐量最大化的效果。 Paralle Old收集器出现后，“吞吐量优先”收集器有了比较名副其实的应用组合（Parallel Scavenge + Parallel Old）。 CMS 收集器CMS (Cocurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器。 CMS收集器基于“标记－清除”算法实现，整个过程分为以下4个步骤： 初始标记（ CMS initial mark ） 标记GC Roots能直接关联到的对象，速度较快 并发标记（ CMS concurrent mark ） GC Roots Tracing的过程 重新标记（ CMS remark ） 修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录 停顿时间比初始标记阶段稍长，远比并发标记时间短 并发清除（ CMS concurrent sweep ） CMS收集器运行示意图 整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以和用户线程一起工作。 优点 并发收集。从整体上说，CMS收集器内存回收过程是与用户线程一起并发执行的 低停顿 缺点 对CPU资源非常敏感 在并发阶段，会因为占用了一部分CPU资源导致应用程序变慢，总吞吐量降低 当CPU数量较少时，CMS对用户程序的影响可能很大 无法处理浮动垃圾（Floating Garbage） 浮动垃圾：CMS并发清理阶段，用户线程产生的未被标记的新的垃圾 CMS无法在当次收集中处理浮动垃圾，只能留待下一次GC时再清理 可能出现“Concurrent Mode Failure”导致另一次Full GC的产生 基于“标记－清除”算法，收集结束时会产生大量空间碎片 G1 收集器G1（ Gabage-First ）是一款面向服务端应用的垃圾收集器。 与其他GC收集器相比，G1具备如下特点： 并行与并发 充分利用多CPU、多核环境下的硬件优势，缩短Stop-The-World的时间 部分其他收集器原本需要停顿Java线程执行的GC动作，G1仍然可以通过并发方式让Java程序继续执行 分代收集 不需要其他收集器配合就能独立管理整个Java堆 能够采用不同方式处理新创建对象和已经存活一段时间的对象 空间整合 从整体上看是基于“标记－整理”算法实现的收集器 从局部（两个Region之间）上看是基于“复制”算法实现的 两种算法都意味着G1运作期间不会产生内存空间碎片 可预测的停顿 降低停顿时间是G1和CMS共同的关注点 G1能建立可预测的停顿时间模型 使用G1收集器时，它将整个Java堆划分为多个大小相等的独立**区域 ( Region )**，虽然保留有新生代和老年代的概念，但它们之间不再是物理隔离的，都是一部分Region（不需要连续）的集合。 G1收集器可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的的价值大小，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。 G1收集器运作大致可划分为以下几个步骤（不计算维护Remembered Set的操作）： 初始标记 ( Initial Marking ) 标记GC Roots能直接关联到的对象 修改TAMS ( Next Top at Mark Start ) 的值，让下一阶段用户程序能在正确可用Region中创建新对象 需要停顿线程，耗时短 并发标记 ( Concurrent Marking ) 从GC Roots开始对堆中对象进行可达性分析，找出存活的对象 可与用户程序并发执行 最终标记 ( Final Marking ) 修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录 虚拟机将对象变化记录在线程Remembered Set Logs里，本阶段把其中数据合并到Remembered Set中 需要停顿线程，可并行执行 筛选回收 ( Live Data Counting and Evacuation ) 对各个Region的回收价值和成本进行排序，根据用户期望GC停顿时间制定回收计划 可以做到与用户程序并发执行，但停顿用户线程将大幅提高收集效率，而且时间用户可控 G1 收集器运行示意图","link":"/2018/05/05/Java-GC/"},{"title":"2018微软预科生面试经历","text":"原本打算大三暑假结束后再找实习，但是大部分企业只在上半年统一招收实习生，担心暑假之后没有什么好的实习可以找，而腾讯阿里都过了实习生招聘的时间。恰逢微软（苏州）进校现场招聘，于是就投了微软。 线上面试原本定的是5月22日在费彝民楼面试，微软之后又改到了5月28日。由于报名人数较多，因此在线下面试前又进行了一次线上面试。 线上面试大概经历了35分钟，比我想的要快了一些，但涉及到的内容还是挺多的。 自我介绍与项目首先是自我介绍，我大概说了一些自己的情况和擅长的领域。面试官说看我的学习成绩不错，是不是平时比较专注于学习，因为他看到我简历上项目只写到17年9月份，还问我是不是最新的简历。我提示他说我简历也有写18年的项目（回去之后就把项目改成了时间顺序）。 接下来就就是介绍一个自己写过的项目，我讲了最近个人完成的JavaEE课程项目，恰好项目部署在服务器上，就把URL发给了面试官，他看了之后表示还不错。 白板代码算法题很简单，一道链表相关的题目： 去除已排序链表中的重复元素。 当时写的代码： 1234567891011121314151617public Node removeDuplicate(Node head) { if (head == null) return head; Node p = head, next = head.next; int num = p.val; while (next != null) { if (next.val == num) { next = next.next; continue; } p.next = next; p = next; next = next.next; num = p.val; } p.next = null; return head;} 现在回过头来看其实多定义了一个num变量，可以直接替换成p.val。 写完之后面试官让我写几个测试用例，也就是几个用于测试的链表。我在写的过程中意识到一开始少了return语句前的一句p.next = null;，也就是没有处理最后一个元素（失误），及时添加了上去。 排序与复杂度下面面试官直接问我有没有学过判断算法时间复杂度，说一下几种排序算法的时间复杂度。在我说到快速排序的平均时间复杂度是O(nlogn)时，面试官让我解释一下为什么说是平均。 设计模式下面面试官让我说一下项目中用过一些设计模式。我讲了工厂模式，在项目关于对象的创建是Spring管理的。他说不用考虑具体项目，说一个印象最深的策略模式。我介绍了一下策略模式，解释了一下策略模式的优点。 ArrayList与LinkedList面试官提的问题之间似乎没有什么关联，接下来问了ArrayList和LinkedList的区别和实现机制，当我说到ArrayList会动态扩大数组时，面试官让我解释一下动态扩张数组的原理，我不确定他要问的原理有多深，而且我并没有看过ArrayList源码，因此我说对具体实现不太了解，面试官也就没有继续问下去。 LRU Cache最后面试官问了LRU Cache，让我简单实现一个LRU Cache，我表示对LRU算法有了解，但是不记得具体实现。面试官让我按自己的理解写，我先说了自己的思路，一开始想的使用队列（说完意识到不对），面试官提示用LinkedList还是ArrayList，由于涉及到频繁的删除与插入操作，当然选择了LinkedList，接下来面试官问LinkedList查找的效率，O(n)明显比不上ArrayList，我想了之后说可以用Map来简化查找过程，key是Cache中的内容，value是指向LinkedList中元素的指针。面试官表示可以，之后也没让我再写代码。 后来发现本题是LeetCode上的原题LRU-Cache，可以使插入和查找时间均为O(1)，思路很巧妙。 线上面试总结总的来说线上面试的内容还是比较简单的，毕竟只是线下面试前一轮的筛选工作，不过因为是第一次面试难免有点紧张，给自己发挥打个7分吧。 线下面试一面一面的面试官是个挺年轻的小伙子，自我介绍之后让我介绍一个的项目，我讲了花旗杯的项目。接着问了我Restful API是如何设计的，对账目的自动归类、数据库的Schema设计等细节问题，问得还是比较细的。 接下来手写算法题是： 假设二叉树的每一个节点都有一个指向父节点的指针，现在任给一个节点，找到这棵树的中序遍历中此节点的下一个节点。 简单思考了一下，分了两种情况，节点有右子树和没有右子树，顺利写完了代码。第一次写完有点小错，被面试官要求再检查一下的时候发现了错误及时改了过来。 二面二面面试官是个小姐姐，比一面感觉亲切很多。一开始同样自我介绍然后讲项目，我还是讲的花旗杯的项目，跟一面比问的问题并不是很多。小姐姐还对云计算的项目表现出了一些感兴趣，问我懂不懂Hadoop，我说不是特别了解。 二面一开始问的似乎是一道智力题： 有25匹马，5个赛道，最少要比多少次能够找出最快的5匹马？ 这题我确实想了很久，一开始给出的想法是，先分5组比5次，把每次里最快的拿出来再比一次，得出25匹马中最快的一匹，把最快的一匹马一开始所在组的第二拿出来再跟另外四匹比，得出第二快的一匹，由此类推。很容易想到的方法，但是比的次数不是最少的。 后来想可以用到排除法，经过小姐姐的提醒，前5组中最快的5匹比过之后，最慢的那匹所在组的后4匹不可能进前5，全部淘汰，同理，可以排除掉4+3+2+1=10匹马。然后小姐姐也没让我继续算下去，直接做算法题了。 找出二叉树中两个节点的最近公共父节点。 第一个想到的方法是，找出从根到这两个节点的路径，存在两个列表中，然后列表中的项两两一一比对，时间复杂度为O(n)。 一时想不出更好的方法，小姐姐就让我写了这种方法的代码。当时觉得时间已经过了挺久，所以写的时候有比较急，递归方法里写的有点乱。 本题也是Leetcode中的原题Common-Ancestor，有更好的递归解决方法。 三面三面面试官是个挺和蔼的大叔（并不是老外，松了一口气），人很好。同样的自我介绍，他直接问了项目经历里第一个JavaEE项目，问我如果管理员想查看所有在线用户该怎么做，我一开始想的是把登录状态存数据库，但由于是Web项目，显然不太合理。于是想到监控Session，用Map存储在线用户的Session，他问我Map放在哪里，让我大概写一下如何实现。我写了一个简单的接口和实现类。 三面算法第一题： 把二叉查找树中一个节点的值变为原来的2倍。 二叉查找树的问题，想了想也就是一次删除和一次插入的操作，分别写了两个方法。 三面算法第二题： 给一个m*n的矩形，每一格有一个正整数值，从左上角开始走到右下角，每一次可以向上下左右四个方向走，问走到右下角所有路径中数字和的最小值以及对应的路径。 总算不是树的问题了，一开始我以为是一道典型的动态规划题（只能向下或向右走），听了描述之后发现不对。一时没想到什么好办法，用递归回溯暴力穷举写完了。（一开始的时候只求了最小值，并没有记录路径，后来面试官说要求得出路径，于是把代码怎么改大概描述了一下）。 问了几个问题，面试官说他是志愿者，也都不太了解，于是还带我去问了HR，人确实很不错。 总结三次面试都是手写算法，而且写了三次二叉树··· 总的来说题并不变态，想不到最优解法的话，基本的方法还是能想到的，多做一做LeetCode很有好处，手写代码最好提前写一写，不然可能像我二面的时候一样这儿插一点那儿涂一点看起来很乱。","link":"/2018/05/28/microsoft-interview/"},{"title":"2018清华软院推免经历","text":"2018年9月28日，我接受了清华大学的待录取通知，两个多月的保研奔波也最终尘埃落定。保研的过程对我来说真的是一波三折，好在最后还是得到了一个满意的结果。 机试清华推免机试语言统一使用C++，电脑环境为Windows，会预装 CLion 和 Visual Studio，并提前创建好了项目，考试时仅需在题目对应项目下的cpp文件中编写代码即可。 机试考试时间为3小时，试题一共3道，题目会打印在纸上发给大家，整个机试体验总体还是不错的。 日历转换 有一种不同的历法，它的一天和目前历法中一天的长度相同，每天有10个小时，每小时100分钟，每分钟100秒，同时一年有10个月，一个月有10个星期，一个星期有10天，现在需要把当前历法中的时间转换为这种历法中的时间。规定当前历法的开始时间为2000-1-1 0:0:0，对应新历法中的0-1-1 0:0:0，秒数向下取整，需要考虑闰年。输入：当前历法的某时刻输出：对应新历法的时刻 第一题送分，但是一开始没注意题目中一天的时间相同，所以一开始结果和给的用例一直对不上，导致浪费了不少时间。 麦森数 形如2p-1的素数被称为麦森数，这时p也一定是个素数，但反过来不一定，即如果p是个素数，2p-1不一定也是素数。到1998年底，人们已经找到了37个麦森数，最大的是p=3021377，它有909526位。输入p (1000 &lt; p &lt; 3100000)，计算2p-1的位数和最后500位数字。 快速幂+大数乘法，只用处理最后500位的乘法，数的位数为 [p*lg2] + 1。 打气球LeetCode原题：312. Burst Balloons 考完才知道是LeetCode上的原题，动态规划，考试时时间不够没想到递推式，还是怪自己刷题不够多··· 面试面试安排在笔试后第二天上午，一共六十多人，分成了五个教室，我在的教室有五个老师和一个助教，助教会帮忙给老师发简历以及记录面试过程。 首先是自我介绍，同时老师会查看简历。老师会轮流问问题，主要是有关简历上的项目，以及一些基础知识（老师会看着成绩单和简历问问题）。问题包括： 你的项目中用到了Hadoop，性能如何？ 项目名称中的“智能“体现在哪里？ 推荐系统是如何实现的？ 你们处理的数据量并不算大，为什么要用Hadoop？ 你说对网络比较感兴趣，网络包括几层，有哪些协议？ 解释编译原理中的自动机、上下文无关文法。 （英文）解释快速排序。 （英文）快速排序中基准如何选取？ 你的项目名中大多包含“智能”两个字，你对智能有什么看法？ 面试过程中有老师根据简历上的链接访问了我的个人网站，看到我的微软面试经历就问了我在微软做了些什么，看了我的Github主页，让我介绍了几个pin的仓库。 总的来说面试的过程还算比较轻松，全程都处在一种聊天的氛围中。回答总的还算顺畅，除了被问到编译原理概念时有点记不清了，感觉问问题的老师有些不太满意··· 总结总结下来，机试题整体难度不算大，但也需要一定的刷题量，搞过ACM的同学机试应该很占优势，机试时也有大佬提前交卷，面试问的问题其实都很基础，老师会问你考的比较好的科目的问题，不会刻意为难你。","link":"/2018/09/28/tsinghua-university/"},{"title":"LeetCode 2019 秋季编程大赛总结","text":"2019 力扣杯全国秋季编程大赛 算是我大学以来第一次参加的算法编程比赛。由于并没有接触过算法竞赛方面的知识，总体感觉是五道题难度跨越特别大，前三题花了不到半个小时，后面的时间几乎都用在最后一题上。 题解1. 猜数字 小A 和 小B 在玩猜数字。小B 每次从 1, 2, 3 中随机选择一个，小A 每次也从 1, 2, 3 中选择一个猜。他们一共进行三次这个游戏，请返回 小A 猜对了几次？ 输入的guess数组为 小A 每次的猜测，answer数组为 小B 每次的选择。guess和answer的长度都等于3。 送分题，代码如下： 123456789class Solution { public int game(int[] guess, int[] answer) { int res = 0; for (int i = 0; i &lt; 3; i++) if (guess[i] == answer[i]) res++; return res; }} 2. 分式化简 化简如下分式： $$a_0+\\frac{1}{a_1+\\frac{1}{a_2+\\frac{1}{\\cdots}}}$$ 输入的cont代表连分数的系数（cont[0]代表上式的a0，以此类推）。返回一个长度为2的数组[n, m]，使得连分数的值等于n / m，且n, m最大公约数为1。 模拟题，从最里面的分式开始计算，题目中说明了cont[i] &gt;= 0，因此不用考虑负数情况（当时在比赛时没有注意这一点，因此为考虑负数多花了些时间），最后分子分母同时除以最大公因数。 12345678910111213141516171819class Solution { private int gcd(int a, int b) { return b == 0 ? a : gcd(b, a % b); } public int[] fraction(int[] cont) { int up = 1, down = cont[cont.length - 1]; for (int i = cont.length - 2; i &gt;= 0; i--) { int a = cont[i]; up += a * down; int tmp = up; up = down; down = tmp; } int gcd = gcd(up, down); return new int[]{down / gcd, up / gcd}; }} 3. 机器人大冒险 力扣团队买了一个可编程机器人，机器人初始位置在原点(0, 0)。小伙伴事先给机器人输入一串指令command，机器人就会无限循环这条指令的步骤进行移动。指令有两种： U: 向y轴正方向移动一格 R: 向x轴正方向移动一格。 不幸的是，在 xy 平面上还有一些障碍物，他们的坐标用obstacles表示。机器人一旦碰到障碍物就会被损毁。 给定终点坐标(x, y)，返回机器人能否完好地到达终点。如果能，返回true；否则返回false。 模拟题，机器人若能走到终点，那么需要的指令数一定恰好等于 x+y，模拟 x+y 次后判断是否处于终点位置，如果中途遇到障碍或者走出 (x, y) 范围则提前结束。 一开始将所有障碍坐标保存在 Map 中，用于加速判断当前坐标是否处在障碍上。 比赛中的一次罚时是因为最后直接 return true 没有判断是否位于终点… 做简单题也一定要细心不能大意。 1234567891011121314151617181920212223242526class Solution { public boolean robot(String command, int[][] obstacles, int x, int y) { Map&lt;Integer, Set&lt;Integer&gt;&gt; obsMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; obstacles.length; i++) { int x1 = obstacles[i][0]; int y1 = obstacles[i][1]; if (!obsMap.containsKey(x1)) { obsMap.put(x1, new HashSet&lt;&gt;()); } obsMap.get(x1).add(y1); } int curX = 0, curY = 0; for (int i = 1; i &lt;= x + y; i++) { char step = command.charAt((i - 1) % command.length()); if (step == 'U') curY += 1; else curX += 1; if (obsMap.containsKey(curX) &amp;&amp; obsMap.get(curX).contains(curY)) return false; if (curX &gt; x || curY &gt; y) return false; } return curX == x &amp;&amp; curY == y; }} 4. 覆盖 你有一块棋盘，棋盘上有一些格子已经坏掉了。你还有无穷块大小为1 * 2的多米诺骨牌，你想把这些骨牌不重叠地覆盖在完好的格子上，请找出你最多能在棋盘上放多少块骨牌？这些骨牌可以横着或者竖着放。 输入：n, m代表棋盘的大小；broken是一个b * 2的二维数组，其中每个元素代表棋盘上每一个坏掉的格子的位置。 输出：一个整数，代表最多能在棋盘上放的骨牌数。 限制： 1 &lt;= n &lt;= 8 1 &lt;= m &lt;= 8 0 &lt;= b &lt;= n * m 这题在比赛时并没有什么思路，后来看题解可以用状态压缩DP或者二分图匹配来做，二分图匹配的方法很巧妙，之后有空会把代码补上。 5. 发 LeetCoin题目描述很长，可以看此链接。 大意是说有一棵树（不一定是二叉树），树上的每个节点代表一个员工，树的层次就代表上下属关系。现在可以进行三种操作： 给某个节点（员工）发一定数量硬币。 给某棵子树的所有节点都发一定数量硬币。 查询某棵子树所有节点的硬币之和。 程序需要尽可能高效地完成这三种操作。 在执行具体操作前，我建立的数据结构包括： all 数组：来记录每个节点的硬币数，初始均为0 father 数组：记录每个节点的父节点编号（类似并查集中的数组） sons Map：记录每个节点的所有直接子节点集合 totalSons 数组：记录以每个节点为根的子树一共有多少节点。这里会用 countSons() 函数递归计算。 当执行操作1时，步骤如下： 将 all 中对应节点硬币数增加； 在 all 数组中依次更新当前节点父节点的硬币数，直到到达根节点，这里会用到 father 数组。 当执行操作2时，步骤如下： 使用 update() 函数递归更新当前节点子树中所有节点硬币数，在更新时，使用 totalSons 数组可以直接计算出当前节点硬币数应该增加多少。 与操作1类似，依次更新父节点硬币数，不过这里更新时增加的值（addFatherCoin）与1中有所不同。 具体实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class Solution { private int countSons(int k, Map&lt;Integer, Set&lt;Integer&gt;&gt; sons) { if (!sons.containsKey(k) || sons.get(k) == null || sons.get(k).isEmpty()) return 0; Set&lt;Integer&gt; sonSet = sons.get(k); int res = sonSet.size(); for (Integer son : sonSet) { res += countSons(son, sons); } return res; } private void update(int num, int coin, int[] totalSons, int[] all, Map&lt;Integer, Set&lt;Integer&gt;&gt; sons) { all[num] = (all[num] + coin) % 1000000007; if (totalSons[num] == 0) return; all[num] = (all[num] + totalSons[num] * coin % 1000000007); for (int son : sons.get(num)) { update(son, coin, totalSons, all, sons); } } public int[] bonus(int n, int[][] leadership, int[][] operations) { int[] all = new int[n + 1]; int[] father = new int[n + 1]; Map&lt;Integer, Set&lt;Integer&gt;&gt; sons = new HashMap&lt;&gt;(); father[1] = -1; for (int i = 0; i &lt; leadership.length; i++) { int a = leadership[i][0]; int b = leadership[i][1]; father[b] = a; if (!sons.containsKey(a)) sons.put(a, new HashSet&lt;&gt;()); sons.get(a).add(b); } int[] totalSons = new int[n + 1]; for (int i = 0; i &lt; n; i++) { totalSons[i + 1] = countSons(i + 1, sons); } List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; operations.length; i++) { int op = operations[i][0]; int num = operations[i][1]; if (op == 1) { int coin = operations[i][2]; all[num] = (all[num] + coin) % 1000000007; int cur = father[num]; while (cur != -1) { all[cur] = (all[cur] + coin) % 1000000007; cur = father[cur]; } } else if (op == 2) { int coin = operations[i][2]; update(num, coin, totalSons, all, sons); int addFatherCoin = coin * (totalSons[num] + 1) % 1000000007; int cur = father[num]; while (cur != -1) { all[cur] = (all[cur] + addFatherCoin) % 1000000007; cur = father[cur]; } } else { res.add(all[num]); } } int[] resArr = new int[res.size()]; for (int i = 0; i &lt; res.size(); i++) resArr[i] = res.get(i); return resArr; }} 后续可能由于这次是 LeetCode 第一次举办的全国大赛所以大佬们并没有关注的原因，我最后竟然正好是第50名（能拿到奖品的最后一名） 。 第 1 名选手获得《计算机程序设计艺术》卷 1 - 卷 4A ；第 2-5 名选手，优先随机挑选以下图书，第 6-50 再做选择，数量有限，先选先得，图书包含：《程序员面试金典 · 第六版》、《算法 4》、《挑战程序设计 2》、《Python 深度学习》、《C++ Primer中文版（第5版）》、《Python机器学习手册：从数据预处理到深度学习》、《Effective C++：改善程序与设计的55个具体做法（第三版）》、《Python编程之美：最佳实践指南》、《Code：隐匿在计算机软硬件背后的语言（英文版）》。 虽然只剩下最后两本书可以选了，不过还是挺开心的。选了一本《程序员面试金典》，很快就收到了书，厚厚的一大本，之后找工作的时候有东西看了~","link":"/2019/10/14/leetcode-autumn-contest/"},{"title":"kdevtmpfsi 进程占用 CPU 问题","text":"今天用实验室电脑（Arch Linux 系统）训练模型时发现训练一个 epoch 的时间比往常要慢得多。使用top指令发现有名为 kdevtmpfsi 的进程 CPU 占用率达到 500%，且直接使用 kill -9 pid 杀死后还会重复出现。 12 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 619970 huangxi+ 20 0 3025392 2.3g 2712 S 582.4 14.8 47:36.78 kdevtmpfsi 问题排查根据网上资料[1]显示，kdevtmpfsi 进程为挖矿程序。 通过 ps -ef | grep kdevtmpfsi 可以获知该进程的 pid，然而在用 kill -9 pid 杀死进程后不久又会重新出现，因此必然是有另一个程序会不断重新启动该进程。 查看定时任务根据分析，有可能是恶意程序在 Linux 中注册了定时任务。查看 Cron Arch wiki 得知，Arch 中默认使用 systemd/Timers 管理定时任务。 通过 systemctl list-timers 查看所有启动的定时任务，输出如下： 1234567NEXT LEFT LAST PASSED UNIT ACTIVATES Sun 2020-10-18 00:00:00 CST 6h left Sat 2020-10-17 00:00:46 CST 17h ago man-db.timer man-db.service Sun 2020-10-18 00:00:00 CST 6h left Sat 2020-10-17 00:00:46 CST 17h ago shadow.timer shadow.service Sun 2020-10-18 14:03:53 CST 20h left Sat 2020-10-17 14:03:53 CST 3h 44min ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service3 timers listed.Pass --all to see loaded but inactive timers, too. 并没有发现异常的定时任务。 守护进程由此可以怀疑是有守护进程在不断重启 kdevtmpfsi 进程。使用 systemctl status pid （pid 为 kdevtmpfsi 进程id）查看后发现， /var/tmp/kinsing 与 /tmp/kdevtmpfsi 进程处于同一 CGroup 中。 分别使用 kill -9 杀死这两个进程并删除系统中对应的文件，之后 kdevtmpfsi 进程就不会再次出现了。 原因分析从网络上资料来看，基本上都是服务器遭受了该进程的影响，而我的环境是实验室里的PC机，并且并没有打开 sshd 服务。 之后分析发现，被攻击的原因很可能是我在电脑上开了一晚上的 Flink 本地集群。在[3]的其中一个回答中也表示是在启动了 Flink 集群后遇到了这个问题。Flink 集群启动后默认会在 8081 端口部署 web UI，通过 web UI 可以提交用户自定义 Job 在集群中执行。因此攻击者应该是通过 Flink web UI 暴露的端口实施了攻击。 通过查看 Flink standalonesession 的 log，发现的确在凌晨有记录一些异常信息： flink-huangxiao-standalonesession-0-huangxiao-lab.log >folded12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697982020-10-17 00:09:40,372 WARN org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint [] - Unhandled exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 00:09:41,896 ERROR org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler [] - Caught exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 03:17:44,446 WARN org.apache.flink.runtime.webmonitor.handlers.JarRunHandler [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.2020-10-17 03:17:44,464 INFO org.apache.flink.client.ClientUtils [] - Starting program (detached: true)2020-10-17 03:17:44,486 ERROR org.apache.flink.runtime.webmonitor.handlers.JarRunHandler [] - Exception occurred in REST handler: No jobs included in application.2020-10-17 06:26:13,712 WARN org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint [] - Unhandled exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 06:26:15,227 ERROR org.apache.flink.runtime.rest.handler.legacy.files.StaticFileServerHandler [] - Caught exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?]2020-10-17 16:47:29,283 WARN org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint [] - Unhandled exceptionjava.io.IOException: Connection reset by peer at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:233) ~[?:?] at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?] at org.apache.flink.shaded.netty4.io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:247) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1140) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) [flink-dist_2.11-1.11.2.jar:1.11.2] at org.apache.flink.shaded.netty4.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [flink-dist_2.11-1.11.2.jar:1.11.2] at java.lang.Thread.run(Thread.java:834) [?:?] 所以说，不管是在个人 PC 还是服务器上部署 Flink 集群后，都是很有可能受到攻击的，需要提前做好准备和防御的措施。 参考资料 [1] https://bbs.huaweicloud.com/blogs/149758[2] https://blog.csdn.net/u014589116/article/details/103705690[3] https://stackoverflow.com/questions/60151640/kdevtmpfsi-using-the-entire-cpu","link":"/2020/10/17/kdevtmpfsi/"},{"title":"博客主题切换 TeXt -&gt; icarus","text":"这两天将博客风格从 TeXt 切换到了 icarus。切换的原因主要是因为 TeXt 的作者有很长一段时间没有更新了，所以最新的 release 版本存在的 bug 一直无法得到解决。 同时。随着主题更换，博客框架也从 Jekyll 切换到了 Hexo。 Hexo 使用Hexo 是基于 Node.js 的博客框架，其官方文档整体感觉比 Jekyll 要友好许多，对中文也有很好的支持。 Hexo 命令 也都比较简单好用，这里可能会用得比较多的有： hexo clean：清除缓存和已生成的静态文件 hexo generate：生成静态文件 hexo server：启动本地服务器，本地端口为4000 hexo deploy：部署网站 icarus 主题icarus 主题 是我在 Github 上搜索后发现星标比较多的一个主题，整体感觉非常清爽，同时能够展示的信息也应有尽有。icarus 的文档是通过其示例页面以博客的形式给出的，内容也十分详细，且同时包含了中英文。 这里仅仅记录一些我认为比较有用的配置项： 代码折叠在 markdown 文件中，使用如下语法来折叠代码块： 123{% codeblock &quot;可选文件名&quot; lang:代码语言 &gt;folded %}...code block content...{% endcodeblock %} 侧边栏位置固定在 _config.icarus.yml 中配置： 12345sidebar: left: sticky: false right: sticky: true 此配置会对全局生效，如果仅仅想对具体文章的页面配置，需要创建 _config.post.yml 文件并在其中配置，一般来说会将目录项所在侧边栏固定。 博客文章显示 toc需要在每篇博客的 format-matter 中添加 toc: true 数学公式显示需要在 _config.icarus.yml 中开启插件： 12plugins: mathjax: true 页面布局宽度配置 页面宽度定义样式文件：&lt;icarus_directory&gt;/include/style/responsive.styl 挂件定义文件：&lt;icarus_directory&gt;/layout/common/widgets.jsx 主内容定义文件：&lt;icarus_directory&gt;/layout/layout.jsx 通过修改 CSS 类名中的数字改变挂件或主内容占据的栏数。数字后的屏幕尺寸，如tablet和widescreen，指代着栏数量生效的屏幕尺寸条件。 修改类名中的数字使主内容栏的栏数量和所有挂件栏的栏数量在相同屏幕尺寸下相加等于12。 从 Jekyll 切换到 Hexo这里在 Hexo 文档中也有描述，需要将原 _post 目录中的所有文件复制到 source/_posts 目录中，并且在 _config.yml 中修改 new_post_name 参数： 1new_post_name: :year-:month-:day-:title.md 在这之后还需要将原博客中存储的图片复制到 source 目录下，同时注意修改博客内容中对图片的引用路径。 随着主题的切换，在原先主题的 markdown 文件中的一些语法可能在新的主题下并不生效（比如原来主题对 emoji 的支持），需要将博客内容再做一遍检查。 博客部署Github Page 不提供对 Hexo 的原生支持，因此我们要手动将 hexo 生成的静态页面部署到 Github 仓库中。这里我尝试使用了 Github Actions 提供的自动部署功能，但是并没有生效… 所以目前还是用的手动部署的方法。 博客源代码我放在 source 分支下，生成的静态页面放在 master 分支。 这里需要安装 hexo-deployer-git 1$ npm install hexo-deployer-git --save 同时修改 _config.yml 中内容： 1234deploy: type: git repo: &lt;repository url&gt; branch: master 之后每次更新内容后，通过 hexo clean &amp;&amp; hexo deploy 就可以将最近静态文件部署到 master 分支。 关于 Github Action 以及目前没能生效的原因，如果之后有时间的话会研究一下~","link":"/2020/10/19/icarus-theme/"},{"title":"虚拟机类加载机制","text":"“代码编译的结果从本地机器码转变为字节码，是存储格式发展的一小步，却是编程语言发展的一大步。” —— 周志明 《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 以下内容整理自周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 类加载机制：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换、解析和初始化，最终形成可以被虚拟机直接使用的Java类型。 类加载时机类的生命周期 加载 Loading 连接 Linking 验证 Verification 准备 Preparation 解析 Resolution 初始化 Initialization 卸载 Unloading 其中，加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序开始（并非进行 或 完成）。解析阶段在某些情况下可以在初始化阶段之后再开始，为了支持Java语言的运行时绑定。 必须对类进行初始化的情况虚拟机严格规定有且只有以下5种情况必须立即对类进行初始化（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令，如果类没有进行过初始化，则需要先触发其初始化。典型场景： 使用new关键字实例化对象时 读取或设置一个类的静态字段时（被final修饰的静态字段除外） 调用一个类的静态方法时 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 初始化一个类时，如果其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个主类。 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 主动引用和被动引用 主动引用：以上五种场景中的行为称之为对一个类进行主动引用 被动引用：除主动引用外，所有引用类的方式称为被动引用，不会触发类初始化，常见例子： 通过子类引用父类的静态字段，不会导致字类初始化 通过数组定义来引用类，不会触发此类初始化 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，不会触发定义常量的类的初始化 接口与类加载过程的区别 接口也有初始化过程 在第3种类需要开始初始化的场景中，接口在初始化时，并不要求其父接口全部都完成了初始化，只有在用到父接口的时候才会初始化。 类加载过程加载在加载阶段，虚拟机需要完成以下3件事情： 通过一个类的全限定名获取定义此类的二进制字节流 未指明从何处、怎样获取。应用实例： 从ZIP包中读取：JAR、EAR、WAR 从网络中获取：Applet Proxy，代理类的二进制字节流 由其它文件生成：JSP 从数据库中读取 对于非数组类，开发人员可以通过自定义的类加载器控制字节流的获取方式。 对于数组类，由Java虚拟机直接创建。遵循以下规则： 数组组件类型是引用类型，递归采用加载过程加载组件类型，数组C将在加载该组件类型的类加载器的类名称空间上被标识 数组组件类型不是引用类型，Java虚拟机会把数组C标记为与引导类加载器关联 数组类的可见性与它的组件类型的可见性一致，如果组件类型不是引用类型，数组类的可见性默认为public 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 二进制字节流按照虚拟机所需格式存储在方法区中 方法区中的数据存储格式由虚拟机实现自行定义 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 并未明确规定存储在Java堆中 对于HotSpot虚拟机，Class对象存放在方法区中 注：加载阶段与连接阶段的部分内容是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这两个阶段的开始时间仍然保持着固定的先后顺序。 验证验证阶段的目的：确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 Java语言本身是相对安全的语言（相对于C/C++），但Class文件不一定由Java源码编译而来，在字节码语言层面上，可能会因为载入有害字节流导致系统崩溃，所以验证是虚拟机对自身保护的一项重要工作。 验证阶段大致会完成4个阶段的检验动作 文件格式验证 验证字节流是否符合Class文件格式的规范，并且能被当前版本虚拟机处理 可能包括的验证点： 是否以魔数 0xCAFEBABE 开头 主、次版本号是否在当前虚拟机处理范围之内 常量池中是否有不被支持的常量类型 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量 … 通过这个阶段验证后，字节流进入内存方法区中进行存储，后面3个验证阶段全部是基于方法区的存储结构进行的 元数据验证 对字节码描述的信息进行语义分析，保证其描述的信息符合Java语言规范的要求 可能包括的验证点： 这个类是否有父类（除了java.lang.Object之外） 这个类的父类是否继承了不允许被继承的类（被final修饰的类） 如果这个类不是抽象类，是否实现了其父类或接口中要求实现的所有方法 类中的字段、方法是否与父类产生矛盾 … 字节码验证 通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的 对类的方法体进行的校验分析，例如： 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的 … 符号引用验证 发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在解析阶段中发生 目的是确保解析动作能正常执行 对类自身之外（常量池中的各种符号引用）的信息进行匹配性校验 通常需要检验的内容： 符号引用中通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段 符号引用中的类、字段、方法的访问性是否可被当前类访问 … 如果无法通过验证，将会抛出一个java.lang.IncompatibleClassChangeError异常的子类，如： java.lang.IllegalAccessError java.lang.NoSuchFieldError java.lang.NoSuchMethodError … 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段。 进行内存分配的仅包括类变量（被static修饰的变量） 关于初始值 通常情况下是数据类型的零值 特殊情况：类字段的字段属性表中存在ConstantValue属性，变量会被初始化为ConstantValue属性所指定的值 解析解析阶段是虚拟机将常量池内的符号引号替换为直接引用的过程。 直接引用与符号引用 符号引用（Symbolic References） 以一组符号描述所引用的目标 符号可以是任意形式的字面量 满足使用时能无歧义地定位到目标即可 与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中 直接引用（Direct References） 直接引用可以是： 直接指向目标的指针、相对偏移量 能间接定位到目标的句柄 与虚拟机实现的内存布局相关，引用的目标必定已经在内存中存在 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。后面3种与JDK 1.7新增的动态语言相关。 前4种引用的解析过程 类或接口的解析 假设当前代码所处类为D，要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用，虚拟机完成解析需要以下三个步骤： 如果C不是一个数组类型，虚拟机会把代表N的全限定名传递给D的类加载器去加载类C 如果C是一个数组类型，并且数组的元素类型为对象，会按照第1点的规则加载数组元素类型，接着由虚拟机生成一个代表此数组维度和元素的数组对象 如果上面步骤没有出现任何异常，C在虚拟机中实际上已经成为一个有效的类或接口，但在解析完成之前还要进行符号引用验证，确认D是否具备对C的访问权限。如果发现不具备访问权限，将抛出java.lang.IllegalAccessError异常 字段解析 要解析一个未被解析过的字段符号引用，首先将会对字段表内class_index项中索引的CONSTANT_Class_info符号引用，也就是字段所属的类或接口的符号引用。如果解析成功，将这个字段所属的类或接口用C表示，虚拟机规范要求按照如下步骤对C进行后续字段搜索： 如果C本身包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束 否则，如果在C中实现了接口，将会按照继承关系从下往上递归搜索各个接口和它的父接口，如果接口中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束 否则，如果C不是java.lang.Object的话，将会按照继承关系从下往上递归搜索其父类，如果在父类中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束 否则，查找失败，抛出java.lang.NoSuchFieldError异常 如果查找过程中成功返回了引用，将会对这个字段进行权限验证，如果不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常。 在实际应用中，虚拟机的编译器实现可能会比上述规范要求更加严格。如果有一个同名字段同时出现在C的接口和父类中，或者同时在自己或父类的多个接口中出现，编译器将可能拒绝编译。 类方法解析 类方法解析的第一个步骤与字段解析相同。如果解析成功，将这个方法所属的类用C表示，接下来虚拟机会按照如下步骤进行后续类方法搜索： 类方法和接口方法符号引用的常量定义是分开的，如果在类方法表中发现class_index中索引的C是个接口，直接抛出java.lang.IncompatibleClassChangeError异常 如果通过了第1步，在类C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束 否则，在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束 否则，在类C实现的接口列表及它们的父接口中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果存在匹配的方法，说明类C是一个抽象类，查找结束，抛出java.lang.AbstractMethodError异常 否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError 如果查找过程成功返回了直接引用，将会对这个进行权限验证，如果不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常。 接口方法解析 接口方法也需要解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用。如果解析成功，用C表示这个接口，接下来虚拟机会按照如下步骤进行后续接口方法搜索： 与类方法解析不同，如果在接口方法表中发现class_index中的索引C是类而不是接口，直接抛出java.lang.IncompatibleClassChangeError异常 否则，在接口C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束 否则，在接口C的父接口中递归查找，直到java.lang.Object类（包括Object类）为止，如果有简单名称和描述符都与目标相匹配的方法，则返回这个方法的直接引用，查找结束 否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError异常 由于接口中的所有方法默认都是public的，所以不存在访问权限的问题，因此接口方法的符号引用解析应当不会抛出java.lang.IllegalAccessError异常 初始化在前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中的字节码。 在准备阶段，变量已经赋过一次初始值，在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源。（执行类构造器&lt;clinit&gt;()方法的过程）。 关于&lt;clinit&gt;()方法 &lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并生成的 收集顺序是由语句在源文件中出现的顺序决定的 静态语句块只能访问到定义在静态语句块之前的变量 静态语句块对定义在它之后的变量可以赋值，但不能访问123456789public class Test { static { // 给变量赋值可以正常编译通过 i = 0; // 这句话编译器会提示&quot;非法向前引用&quot; System.out.print(i); } static int i = 1;} &lt;clinit&gt;()方法与实例构造器&lt;init&gt;()方法不同 不需要显式地调用父类构造器，虚拟机会保证父类的&lt;clinit&gt;()方法已经执行完毕 由于父类的&lt;clinit&gt;()方法先执行，父类中定义的静态语句块要优先于子类的变量赋值操作 下例中，字段B的值是2123456789101112static class Parent { public static int A = 1; static { A = 2; }}static class Sub extends Parent { public static int B = A;}public static void main(String[] args) { System.out.println(Sub.B);} &lt;clinit&gt;()方法对于类或者接口来说并不是必须的 如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成此方法 接口与类的&lt;clinit&gt;()方法的异同 接口中不能使用静态语句块，但有变量初始化的赋值操作，因此接口与类一样都会生成&lt;clinit&gt;()方法 接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法，只有当父接口中定义的变量使用时，父接口才会初始化 接口的实现类在初始化时一样不会执行父接口的&lt;clinit&gt;()方法 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁、同步 如果多个线程同时去初始化一个类，只会有一个线程去执行这个类的&lt;clinit&gt;()方法，其他线程需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕 如果一个类的&lt;clinit&gt;()方法中有耗时很长操作，可能造成多个线程阻塞 类加载器虚拟机设计团队把类加载阶段中“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到虚拟机外部去实现，以便让应用程序自己决定去获取所需要的类。实现这个动作的代码模块被称为“类加载器”。 类与类加载器类加载器虽只用于实现类的加载动作，但它在Java程序中起到的作用远远不限于类加载阶段。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性。每个类加载器，都拥有一个独立的类名称空间。 这也就是说，比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义。这里说的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判断等情况。 类加载器的种类从Java虚拟机的角度来讲，只存在两种类加载器： 启动类加载器（Bootstrap ClassLoader） 使用C++实现（仅限于HotSpot） 虚拟机自身的一部分 所有其他的类加载器 虚拟机外部 继承自抽象类java.lang.ClassLoader 从Java开发人员角度来看，类加载器可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器： 启动类加载器（Bootstrap ClassLoader） 将&lt;JAVA_HOME&gt;/lib目录中的，或者被-Xbootclasspath参数指定的路径中的虚拟机识别的类库加载到虚拟机内存中， 无法被Java程序直接引用 如果需要把加载请求委派给引导类加载器，直接使用null即可 扩展类加载器（Extension ClassLoader） 由sun.misc.Launcher $ExtClassLoader实现 负责加载&lt;JAVA_HOME&gt;/lib/ext目录中的，或被java.ext.dirs系统变量所指定的路径中的所有类库 开发者可以直接使用 应用程序类加载器（Application ClassLoader） 由sun.misc.Launcher $AppClassLoader实现 一般也称为系统类加载器 负责加载用户类路径（ClassPath）上所指定的类库 开发者可以直接使用 如果应用程序没有自定义过自己的类加载器，一般默认情况下使用此类加载器 双亲委派模型加载器之间的关系 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。类加载器之间的关系不会以继承关系来实现，而是都使用组合关系来复用父加载器的代码。 工作过程：如果一个类加载器收到了类加载的请求，他首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此。只有当父类加载器反馈自己无法完成这个加载请求时，自类加载器才会尝试自己去加载。 意义： Java类随着类加载器一起具备了带有优先级的层次关系 保证Java程序稳定运作 实现简单，实现双亲委派的代码集中在java.lang.ClassLoader的loadClass()方法之中 破坏双亲委派模型双亲委派模型并不是一个强制性的约束模型，而是Java设计者推荐给开发者的类加载器实现方式。 到目前为止，双亲委派模型出现出3次较大规模的被破坏的情况。 JDK 1.2发布之前 双亲委派模型在JDK 1.2之后才被引入，而类加载器在JDK 1.0已经存在，需要向前兼容 添加了新的protected方法findClass() 模型自身缺陷 基础类可能需要调用回用户代码（JNDI） 解决：线程上下文类加载器（Thread Context ClassLoader） 对程序动态性追求 动态性：代码热替换、模块热部署等","link":"/2018/05/11/class-loader/"},{"title":"Java 内存模型","text":"“并发处理的广泛应用是使得Amdahl定律代替摩尔定律成为计算机性能发展源动力的根本原因，也是人类“压榨”计算机运算能力的最有力武器。“ ——周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 以下内容整理自周志明《深入理解Java虚拟机：JVM高级特性与最佳实践（第2版）》 内存模型在物理计算机中，为了解决缓存一致性问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI、MOSI、Synapse、Firefly、Dragon Protocol等。 内存模型可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。 Java内存模型Java内存模型（Java Memory Model，JMM）试图屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。 注：这里和以下所说的Java内存模型都特指在JDK1.2之后建立起来并在JDK1.5中完备过的内存模型。 主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 变量（Variables）：与Java编程中的变量有所区别，它包括实例字段、静态字段和构成数组对象的元素，不包括局部变量与方法参数，因为后者是线程私有的。 注：如果局部变量是一个reference类型，它引用的对象在Java堆中可被各个线程共享，但是reference本身在Java栈的局部变量表中，它是线程私有的。 主内存（Main Memory）：所有的变量都存储在主内存中，主内存与物理硬件的主内存可以互相类比，但此处只是虚拟机内存的一部分。 工作内存（Working Memory）：每条线程有自己的工作内存，工作内存可与处理器高速缓存类比，线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 注：关于主内存副本拷贝，对象的引用、对象中某个在线程中访问到的字段是有可能存在拷贝的，但不会有虚拟机实现成把整个对象拷贝一次。 内存间交互操作关于主内存与工作内存之间具体的交互协议，Java内存模型定义了以下8中操作来完成： lock（锁定） 作用于主内存变量，把一个变量标识为一条线程独占的状态。 unlock（解锁） 作用于主内存变量，把一个处于锁定状态的变量释放，变量释放后才可以被其他线程锁定。 read（读取） 作用于主内存变量，把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入） 作用于工作内存变量，把read操作从主内存得到的变量值放入工作内存的变量副本中。 use（使用） 作用于工作内存变量，把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量值的字节码指令时将会执行这个操作。 assign（赋值） 作用于工作内存变量，把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储） 作用于工作内存变量，把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入） 作用于主内存变量，把store操作从工作内存中得到的变量值放入主内存的变量中。 把一个变量从主内存复制到工作内存，要顺序地执行read和load操作，把一个变量从工作内存同步回主内存，要顺序地执行store和write操作。Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。 Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则： 不允许read和load、store和write操作之一单独出现 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存 不允许一个线程无原因地（没有发生过任何assign操作）把数据从其工作内存同步回主内存中 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中 这8种内存访问操作以及上述规则限定，再加上volatile的一些特殊规定，就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。 特殊规则——volatile变量关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制。Java内存模型对volatile专门定义了一些特殊的访问规则。 volatile 关键字的作用1. 保证变量对所有线程的可见性 可见性：当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的 volatile变量只能保证可见性，Java中的运算并非原子操作，会导致volatile变量的运算在并发下是不安全的 volatile变量的运算在并发下不安全的例子： 123456789101112131415161718192021222324252627282930public class VolatileTest { public static volatile int race = 0; public static void increase() { race++; } private static final int THREADS_COUNT = 20; public static void main(String[] args) { Thread[] threads = new Thread[THREADS_COUNT]; for (int i = 0; i &lt; THREADS_COUNT; i++) { // JDK1.8后可用Lambda表达式 threads[i] = new Thread(new Runnable() { @Override public void run() { for (int j = 0; j &lt; 10000; j++) { increase(); } } }); threads[i].start(); } // 如果使用IDEA，这里的1需要改为2，因为多了一个Monitor Ctrl-Break线程 while (Thread.activeCount() &gt; 1) { Thread.yield(); } System.out.println(race); }} 在这段代码中发起了20个线程，每个线程对race变量进行10000次自增操作，但运行程序输出的结果都是一个小于200000的数字。由于自增运算race++在Class文件中由4条字节码指令构成，当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此时是正确的，但是执行iconst_1、iadd指令时，其他线程可能已经把race的值加大了，操作栈顶的值变成了过期的数据，所以putstatic指令执行后就会把较小的race值同步回主内存中。 2. 禁止指令重排序优化普通变量仅仅保证在该方法执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。 指令重排序干扰程序并发执行的例子： 123456789101112131415161718Map configOptions;char[] configText;volatile boolean initialized = false;// 假设以下代码在线程A中执行// 模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;// 假设以下代码在线程B中执行// 等待initialized，代表线程A已经把配置信息初始化完成while (!initialized) { sleep();}// 使用线程A中初始化好的配置信息doSomethingWithConfig(); 在上例中，如果定义initialized变量时没有使用**volatile**修饰，就可能会由于指令重排序的优化，导致位于线程A中最后一句的代码initialized = true被提前执行，这样在线程B中使用配置信息的代码就可能出现错误。 **volatile**关键字禁止指令重排序的例子： 12345678910111213141516public class Singleton { private volatile static Singleton instance; private Singleton() {} public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; }} 代码是一段标准的DCL单例代码，观察加入和未加入**volatile关键字所生成汇编代码的差别，关键变化在于有volatile修饰的变量赋值后多执行了一个lock addl $0x0, (%esp)操作，这个操作相当于一个内存屏障**（Memory Barrier，指重排序时不能把后面的指令重排序到内存屏障之前的位置），指令中把ESP寄存器的值加0是一个空操作，IA32手册规定lock前缀的作用是使得本CPU的Cache写入内存，该写入动作也会引起别的CPU或者别的内核无效化其Cache。通过这样一个操作，可以让volatile变量的修改对其他CPU立即可见。 **volatile**能禁止指令重排序是因为CPU在指令重排时需要能正确处理指令依赖情况以保障程序能得出正确的执行结果，而lock addl $0x0, (%esp)指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这样便形成了“指令重排序无法越过内存屏障”的效果。 volatile 变量的特殊规则假定T表示一个线程，V和W分别表示两个volatile类型变量，那么在进行read、load、use、assign、store和write操作时需要满足如下规则： 只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行load动作。 只有当线程T对变量V执行的前一个操作是assign的时候，线程T才能对变量V执行store操作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行assign动作。 假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load或store动作，假定动作P是和动作F相应的对变量V的read或write动作；类似地，假定动作B是线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假定动作Q是和动作G相应的对变量W的read和write操作，如果A先于B，那么P先于Q。 volatile 使用总结volatile**关键字的运用场景**： 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值 变量不需要与其他的状态变量共同参与不变约束 使用例子： 1234567891011volatile boolean shutdownRequested;public void shutdown() { shutdownRequested = true;}public void doWork() { while (!shutdownRequested) { // do stuff }} 在某些情况下，**volatile的同步机制的性能确实要优于锁（使用synchronized关键字或java.util.concurrent包里面的锁），但是由于虚拟机对锁实行的许多消除和优化，使得我们很难量化地认为volatile就会比synchronized快多少。大多数场景下volatile的总开销要比锁低。我们在volatile与锁之中选择的唯一依据仅仅是volatile**的语义能否满足使用场景的需求。 特殊规则——long和double型变量long和double的非原子性协定（Nonatomic Treatment of double and long Variables） Java内存模型要求8个操作都具有原子性，但是对于64位的数据类型——long和double，在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即虚拟机实现可以选择不保证64位数据类型的load、store、read和write这4个操作的原子性。 Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但“强烈建议”虚拟机把这些操作实现为具有原子性的操作。 在实际开发中，各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，因此编写代码时一般不需要把用到的long和double变量专门声明为volatile。 Java内存模型特征Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的。 原子性 (Atomcity)由Java内存模型直接保证的原子性变量操作包括read、load、assign、use、store和write，可以大致认为基本数据类型的访问和读写是具备原子性的。 如果应用场景需要一个更大范围的原子性保证，Java内存模型还提供了lock和unlock操作来满足这种需求，虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反映到Java代码中就是同步块synchronized关键字，在synchronized块之间的操作也具备原子性。 可见性 (Visibility)可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。 Java内存模型通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式实现可见性。普通变量和volatile变量都是如此，它们的区别是，volatile变量保证了多线程操作时变量的可见性，普通变量不能保证这一点。 除了volatile之外，synchronized和final关键字也能实现可见性。 volatile 实现可见性 规则：见 volatile变量的特殊规则 synchronized 实现可见性 规则：对一个变量执行unlock操作之前，必须先把此对象同步回主内存中（执行store、write操作）。 final 实现可见性 被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”引用传递出去，那在其他线程就能看见final字段的值。 有序性 (Ordering)Java程序中天然的有序性：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。 Java语言提供了volatile和synchronized关键字保证线程间的有序性。 volatile 实现有序性 volatile本身包含了禁止指令重排序的语义 synchronized 实现有序性 规则：一个变量在同一时刻只允许一条线程对其进行lock操作，这决定了持有同一个锁的两个同步块只能串行地进入。 先行发生原则Java语言中有一个“先行发生”（happens-before）的原则。这个原则是判断数据是否存在竞争、线程是否安全的主要依据。 先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生于B，其实就是说在发生B操作之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 Java内存模型下有一些天然的先行发生关系，无需任何同步协助就已经存在。如果两个操作之间的关系不在此列，并且无法通过下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意进行重排序。 程序次序规则 (Program Order Rule) 在一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说应该是控制流顺序。 管程锁定规则 (Monitor Lock Rule) 一个unlock操作先行发生于后面对同一个锁的lock操作，“后面”是指时间上的先后顺序。 volatile变量规则 (Volatile Variable Rule) 对一个volatile变量的写操作先行发生于后面对这个变量的读操作，“后面”同样是指时间上的先后顺序。 线程启动规则 (Thread Start Rule) Thread对象的start()方法先行发生于此线程的每一个动作。 线程终止规则 (Thread Termination Rule) 线程中的所有操作都先行发生于对此线程的终止检测，可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。 线程中断规则 (Thread Interruption Rule) 对线程interrupt()方法的调动先行发生于被中断线程的代码检测到终端事件的发生，可以通过Thread.interrupted()方法检测到是否有终端现象。 对象终结规则 (Finalizer Rule) 一个对象的初始化完成先行发生于它的finalize()方法的开始。 传递性 (Transitivity) 如果操作A先行发生于操作B，操作B先行发生于操作C，那么操作A先行发生于操作C。 事件先后顺序与先行发生原则之间基本没有太大的关系，在衡量并发安全问题时，不要受到事件顺序的干扰，一切必须以先行发生原则为准。","link":"/2018/05/24/java-memory-model/"}],"tags":[{"name":"Original","slug":"Original","link":"/tags/Original/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Notes","slug":"Notes","link":"/tags/Notes/"},{"name":"Interview","slug":"Interview","link":"/tags/Interview/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Arch","slug":"Arch","link":"/tags/Arch/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"}],"categories":[]}